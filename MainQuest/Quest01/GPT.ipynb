{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer와 비교해 변경이 필요한 부분\n",
    "- positional encoding을 따로 추가하는게 아니라 Embedding layer에서 같이 학습될 수 있도록 구성해야함\n",
    "- Encoder-Decoder 구조가 아닌 Decoder만 활용한 모델 구조로 변경\n",
    "- masked self Attention만 사용하므로 look ahead mask만 활용\n",
    "- Unsupervised Learning 이므로 pre-training시 target 데이터는 입력 데이터를 right-shift 시킨 형태로 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-17 16:38:26.389599: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-17 16:38:26.904202: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 구조 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### positional encoding을 따로 추가하는게 아니라 Embedding layer에서 같이 학습될 수 있도록 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearnedPositionalEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, max_position, d_model):\n",
    "        super(LearnedPositionalEmbedding, self).__init__()\n",
    "        self.pos_embedding = tf.keras.layers.Embedding(max_position, d_model)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        seq_len = tf.shape(inputs)[1]\n",
    "        position = tf.range(seq_len, dtype=tf.int32)  # (seq_len,)\n",
    "        position_embeddings = self.pos_embedding(position)  # (seq_len, d_model)\n",
    "        position_embeddings = tf.expand_dims(position_embeddings, axis=0)  # (1, seq_len, d_model)\n",
    "        return inputs + position_embeddings\n",
    "\n",
    "\n",
    "class GPTEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, d_model, max_position):\n",
    "        super(GPTEmbedding, self).__init__()\n",
    "        self.token_embedding = tf.keras.layers.Embedding(vocab_size, d_model)\n",
    "        self.position_embedding = LearnedPositionalEmbedding(max_position, d_model)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        token_embeddings = self.token_embedding(inputs)  # (batch, seq_len, d_model)\n",
    "        return self.position_embedding(token_embeddings)  # 위치 인코딩 적용\n",
    "\n",
    "# 사용 예시\n",
    "vocab_size = 10000\n",
    "d_model = 512\n",
    "MAX_Length = 1024 #문장 최대 길이\n",
    "\n",
    "gpt_embedding = GPTEmbedding(vocab_size, d_model, MAX_Length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 스케일드 닷 프로덕트 어텐션 함수\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "  # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
    "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "  # 가중치를 정규화\n",
    "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "  logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "  # 패딩에 마스크 추가\n",
    "  if mask is not None:\n",
    "    logits += (mask * -1e9)\n",
    "\n",
    "  # softmax적용\n",
    "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "  # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
    "  output = tf.matmul(attention_weights, value)\n",
    "  return output\n",
    "\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "    super(MultiHeadAttention, self).__init__(name=name)\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0 # 나누어 떨어지지 않으면 수행 불가\n",
    "\n",
    "    self.depth = d_model // self.num_heads # 여기가 Q,K,V가 muti-head로 나뉘었을 때의 차원 수\n",
    "\n",
    "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.value_dense = tf.keras.layers.Dense(units=d_model) # 아직 어텐션 계산 전 형태\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(units=d_model)# 다음 레이어로 넘어가는 최종 레이어 \n",
    "\n",
    "  def split_heads(self, inputs, batch_size):\n",
    "    inputs = tf.reshape(\n",
    "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))# -1은 입력 문장의 길이\n",
    "    return tf.transpose(inputs, perm=[0, 2, 1, 3])# (batch_size, num_heads, seq_len, depth)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "        'value'], inputs['mask']\n",
    "    batch_size = tf.shape(query)[0]\n",
    "\n",
    "    # Q, K, V에 각각 Dense를 적용합니다\n",
    "    query = self.query_dense(query)\n",
    "    key = self.key_dense(key)\n",
    "    value = self.value_dense(value)\n",
    "\n",
    "    # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
    "    query = self.split_heads(query, tf.shape(query)[0])\n",
    "    key = self.split_heads(key, tf.shape(key)[0])\n",
    "    value = self.split_heads(value, tf.shape(value)[0])\n",
    "\n",
    "    # 스케일드 닷 프로덕트 어텐션 함수\n",
    "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "    # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
    "    concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))# (batch_size, seq_len, d_model)\n",
    "\n",
    "    # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
    "    outputs = self.dense(concat_attention)\n",
    "\n",
    "    return outputs\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def create_padding_mask(x):\n",
    "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "  # (batch_size, 1, 1, sequence length)\n",
    "  return mask[:, tf.newaxis, tf.newaxis , : ]\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "  seq_len = tf.shape(x)[1]\n",
    "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "  padding_mask = create_padding_mask(x)\n",
    "  return tf.maximum(look_ahead_mask, padding_mask)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### masked self Attention만 사용하므로 look ahead mask만 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 디코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
    "def decoder_layer(units, d_model, num_heads, name=\"decoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행(셀프 어텐션)\n",
    "  attention = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention\")(inputs={\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': look_ahead_mask\n",
    "      })\n",
    "\n",
    "  # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention + inputs)\n",
    "\n",
    "  # 두 번째 서브 레이어 :  Feed Forward  \n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 LayerNormalization 수행\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, look_ahead_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder-Decoder 구조가 아닌 Decoder만 활용한 모델 구조로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def GPT(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            MAX_Length,\n",
    "            name=\"GPT\"):\n",
    "  \n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "\n",
    "  # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
    "  # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "  look_ahead_mask = tf.keras.layers.Lambda(\n",
    "      create_look_ahead_mask,\n",
    "      output_shape=(1, None, None),\n",
    "      name='look_ahead_mask')(inputs)\n",
    "\n",
    "  # 포지셔널 인코딩 + 임베딩 층\n",
    "  embeddings = GPTEmbedding(vocab_size, d_model, MAX_Length)(inputs)\n",
    "\n",
    "  # num_layers만큼 쌓아올린 디코더의 층.\n",
    "  for i in range(num_layers):\n",
    "    outputs = decoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        name=\"decoder_layer_{}\".format(i),\n",
    "    )([embeddings, look_ahead_mask])\n",
    "\n",
    "  # 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(outputs)\n",
    "\n",
    "  return tf.keras.Model(inputs=[inputs], outputs=outputs, name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터셋 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12시 땡!   하루가 또 가네요.      0\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4          PPL 심하네   눈살이 찌푸려지죠.      0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('ChatbotData.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                          12시 땡!\n",
       "1                     1지망 학교 떨어졌어\n",
       "2                    3박4일 놀러가고 싶다\n",
       "3                 3박4일 정도 놀러가고 싶다\n",
       "4                         PPL 심하네\n",
       "                   ...           \n",
       "23641          티가 나니까 눈치가 보이는 거죠!\n",
       "23642               훔쳐보는 거 티나나봐요.\n",
       "23643                      설렜겠어요.\n",
       "23644    잘 헤어질 수 있는 사이 여부인 거 같아요.\n",
       "23645          도피성 결혼은 하지 않길 바라요.\n",
       "Name: text, Length: 23646, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = pd.concat([data['Q'], data['A']], axis=0).reset_index(drop=True)\n",
    "raw = pd.DataFrame(raw, columns=['text'])\n",
    "raw['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19436"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = raw.drop_duplicates().reset_index(drop=True)\n",
    "len(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에스에스디 제품은 12개의 기능이 있습니다 가격은 1500원\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def english_to_korean(word):\n",
    "    \"\"\"\n",
    "    영어 단어를 한글 발음으로 변환\n",
    "    예) SSD -> 에스에스디\n",
    "    \"\"\"\n",
    "    mapping = {\n",
    "        'a': '에이', 'b': '비', 'c': '씨', 'd': '디', 'e': '이',\n",
    "        'f': '에프', 'g': '지', 'h': '에이치', 'i': '아이',\n",
    "        'j': '제이', 'k': '케이', 'l': '엘', 'm': '엠',\n",
    "        'n': '엔', 'o': '오', 'p': '피', 'q': '큐',\n",
    "        'r': '알', 's': '에스', 't': '티', 'u': '유', \n",
    "        'v': '브이', 'w': '더블유', 'x': '엑스', 'y': '와이', 'z': '제트'\n",
    "    }\n",
    "    return \"\".join(mapping.get(ch.lower(), ch) for ch in word)\n",
    "\n",
    "def preprocess_korean_sentence(sentence, remove_stopwords=True):\n",
    "    \"\"\"\n",
    "    1. 앞뒤 공백 제거\n",
    "    2. 영어 단어는 한글 발음으로 변환 (예: SSD -> 에스에스디)\n",
    "    3. 최종적으로 한글 숫자 이외의 문자들을 제거\n",
    "    \"\"\"\n",
    "    # 1. 앞뒤 공백 제거\n",
    "    sentence = sentence.strip()\n",
    "       \n",
    "    # 2. 영어 변환: [A-Za-z]+ 패턴에 대해 영어 단어를 한글 발음으로 치환\n",
    "    sentence = re.sub(r'[A-Za-z]+', lambda m: english_to_korean(m.group()), sentence)\n",
    "    \n",
    "    # 3. 한글, 숫자, 공백을 제외한 문자 제거\n",
    "    sentence = re.sub(r'[^가-힣0-9\\s]', '', sentence)\n",
    "    \n",
    "    \n",
    "    return sentence\n",
    "\n",
    "# 예시 사용\n",
    "example_text = \"SSD 제품은 12개의 기능이 있습니다. 가격은 1500원.\"\n",
    "print(preprocess_korean_sentence(example_text, remove_stopwords=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'에스디카드 망가졌어'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_korean_sentence(raw.iloc[5]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              text          cleaned\n",
      "0           12시 땡!            12시 땡\n",
      "1      1지망 학교 떨어졌어      1지망 학교 떨어졌어\n",
      "2     3박4일 놀러가고 싶다     3박4일 놀러가고 싶다\n",
      "3  3박4일 정도 놀러가고 싶다  3박4일 정도 놀러가고 싶다\n",
      "4          PPL 심하네          피피엘 심하네\n"
     ]
    }
   ],
   "source": [
    "raw['cleaned'] = raw['text'].apply(preprocess_korean_sentence)\n",
    "print(raw.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cho/anaconda3/envs/GPU/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "살짝 오래 걸릴 수 있어요. 스트레칭 한 번 해볼까요? 👐\n",
      "슝=3 \n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "print(\"살짝 오래 걸릴 수 있어요. 스트레칭 한 번 해볼까요? 👐\")\n",
    "\n",
    "# 질문과 답변 데이터셋에 대해서 Vocabulary 생성\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(raw['cleaned'], target_vocab_size=2**13)\n",
    "print(\"슝=3 \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰에 고유한 정수를 부여합니다.\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TOKEN의 번호 : [9057]\n",
      "END_TOKEN의 번호 : [9058]\n"
     ]
    }
   ],
   "source": [
    "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
    "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9059\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰을 고려하여 +2를 하여 단어장의 크기를 산정합니다.\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 21번째 질문 샘플: [8740, 1932, 3154]\n"
     ]
    }
   ],
   "source": [
    "# 임의의 22번째 샘플에 대해서 정수 인코딩 작업을 수행.\n",
    "# 각 토큰을 고유한 정수로 변환\n",
    "print('정수 인코딩 후의 21번째 질문 샘플: {}'.format(tokenizer.encode(raw.iloc[21]['cleaned'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsAAAAGJCAYAAACEkIXWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB1XklEQVR4nO3deVhUZfsH8O8wzAzrgKhsiojghrtoSiluLCr5ilq5pWio6Q8tJZfodcGlSMqt3Oq11ErT7FXzdQNEccVywz1TxLAENDdkH2bO7w/i5MjiDIIzON/Pdc3VWe55zn3mmRnvDs+cRyIIggAiIiIiIhNhZugEiIiIiIieJxbARERERGRSWAATERERkUlhAUxEREREJoUFMBERERGZFBbARERERGRSWAATERERkUlhAUxEREREJoUFMBERERGZFBbARESkk1GjRsHGxua5HrNhw4YYNWpUtR/nxo0bkEgkWLdunbjteZ+vRCJBVFTUczsekSljAUxEZTp//jxee+01uLu7w8LCAvXq1UNAQAA+//xzQ6dWoyUmJkIikeDHH380dCplys3NRVRUFBITE6u87e7du0MikUAikcDMzAxKpRJNmzbFiBEjEB8fX2XH2b17t9EWksacG5EpMTd0AkRkfI4dO4YePXqgQYMGGDt2LJydnXHz5k0cP34cy5Ytw6RJkwydIlWT3NxczJ07F0BxwVrV6tevj+joaABATk4Orl27hq1bt+K7777DG2+8ge+++w4ymUyMv3LlCszM9LtWs3v3bqxYsUKvQtPd3R15eXlax64OFeWWl5cHc3P+s0z0PPCTRkSlfPjhh7Czs8OJEydgb2+vte/27duGSYpeCHZ2dnjzzTe1tn388cd45513sHLlSjRs2BALFy4U9ykUimrNp6ioCBqNBnK5HBYWFtV6rKcx9PGJTAmHQBBRKSkpKWjRokWp4hcAHB0dS2377rvv4OPjA0tLSzg4OGDIkCG4efNmqbgvv/wSnp6esLS0xEsvvYTDhw+je/fuWlca161bB4lEghs3bmg9t2TowJN/mv/555/Ru3dv2NnZwcrKCt26dcPRo0e1YqKioiCRSHDt2jWMGjUK9vb2sLOzw+jRo5Gbm1vm+bz00kuwsrJCrVq14Ofnh7i4OK2YPXv2oGvXrrC2toatrS2Cg4Nx8eLFUm1V1oMHDzB58mS4ublBoVDAy8sLCxcuhEajEWNKxq1++umn4murUCjQsWNHnDhxolSbW7Zsgbe3NywsLNCyZUts27YNo0aNQsOGDcX26tatCwCYO3euOFzhyauVf/75J0JCQmBjY4O6deti6tSpUKvVlT5XqVSKzz77DN7e3li+fDkePnwo7ntyDLBKpcLcuXPRuHFjWFhYoHbt2ujSpYs4hGLUqFFYsWIFAIj5SySSUq/X0qVLxdfr0qVLZY4BLnH9+nUEBQXB2toarq6umDdvHgRBEPeX9958ss2KcivZ9uRrfebMGfTp0wdKpRI2Njbo1asXjh8/rhVT8pk5evQoIiIiULduXVhbW2PAgAG4c+fO0zuAyATxCjARleLu7o6kpCRcuHABLVu2rDD2ww8/xKxZs/DGG29gzJgxuHPnDj7//HP4+fnhzJkzYhH91Vdf4e2338bLL7+MyZMn4/r16/jXv/4FBwcHuLm5VSrP/fv3o0+fPvDx8cGcOXNgZmaGtWvXomfPnjh8+DBeeuklrfg33ngDHh4eiI6OxunTp7FmzRo4OjpqXXGcO3cuoqKi8PLLL2PevHmQy+X4+eefsX//fgQGBgIAvv32W4SGhiIoKAgLFy5Ebm4uVq1ahS5duuDMmTNiQVlZubm56NatG/7880+8/fbbaNCgAY4dO4bIyEikp6dj6dKlWvEbN27Eo0eP8Pbbb0MikSAmJgYDBw7E9evXxT/p79q1C4MHD0arVq0QHR2N+/fvIywsDPXq1RPbqVu3LlatWoUJEyZgwIABGDhwIACgdevWYoxarUZQUBA6deqETz/9FPv27cOiRYvg6emJCRMmVPqcpVIphg4dilmzZuHIkSMIDg4uMy4qKgrR0dEYM2YMXnrpJWRlZeHkyZM4ffo0AgIC8Pbbb+PWrVuIj4/Ht99+W2Yba9euRX5+PsaNGweFQgEHBwet/7F4nFqtRu/evdG5c2fExMRg7969mDNnDoqKijBv3jy9zlGX3B538eJFdO3aFUqlEtOnT4dMJsMXX3yB7t274+DBg+jUqZNW/KRJk1CrVi3MmTMHN27cwNKlSzFx4kRs3rxZrzyJTIJARPSEuLg4QSqVClKpVPD19RWmT58uxMbGCoWFhVpxN27cEKRSqfDhhx9qbT9//rxgbm4ubi8sLBQcHR2Ftm3bCgUFBWLcl19+KQAQunXrJm5bu3atAEBITU3VavPAgQMCAOHAgQOCIAiCRqMRGjduLAQFBQkajUaMy83NFTw8PISAgABx25w5cwQAwltvvaXV5oABA4TatWuL61evXhXMzMyEAQMGCGq1Wiu25BiPHj0S7O3thbFjx2rtz8jIEOzs7Eptf1LJeWzZsqXcmPnz5wvW1tbCb7/9prX9/fffF6RSqZCWliYIgiCkpqYKAITatWsL9+7dE+N++uknAYDwv//9T9zWqlUroX79+sKjR4/EbYmJiQIAwd3dXdx2584dAYAwZ86cUnmFhoYKAIR58+ZpbW/Xrp3g4+NT4XkLgiB069ZNaNGiRbn7t23bJgAQli1bJm5zd3cXQkNDxfU2bdoIwcHBFR4nPDxcKOuft5LXS6lUCrdv3y5z39q1a8VtJec7adIkcZtGoxGCg4MFuVwu3LlzRxCE0u/NitosLzdBEEq97iEhIYJcLhdSUlLEbbdu3RJsbW0FPz8/cVvJZ8bf31/rszBlyhRBKpUKDx48KPN4RKaMQyCIqJSAgAAkJSXhX//6F86ePYuYmBgEBQWhXr162LFjhxi3detWaDQavPHGG/jrr7/Eh7OzMxo3bowDBw4AAE6ePInbt29j/PjxkMvl4vNHjRoFOzu7SuWYnJyMq1evYtiwYbh796547JycHPTq1QuHDh0qdVVv/PjxWutdu3bF3bt3kZWVBQDYvn07NBoNZs+eXeqHVyV/qo6Pj8eDBw8wdOhQrXOWSqXo1KmTeM7PYsuWLejatStq1aqldQx/f3+o1WocOnRIK37w4MGoVauW1nkBxX+6B4Bbt27h/PnzGDlypNZtvbp164ZWrVrpnV9Zr2PJsZ5FSW6PHj0qN8be3h4XL17E1atXK32cQYMGiUM9dDFx4kRxWSKRYOLEiSgsLMS+ffsqncPTqNVqxMXFISQkBI0aNRK3u7i4YNiwYThy5Ij4vi0xbtw4rSEVXbt2hVqtxu+//15teRLVVBwCQURl6tixI7Zu3YrCwkKcPXsW27Ztw5IlS/Daa68hOTkZ3t7euHr1KgRBQOPGjctso+TP7yX/AD8ZJ5PJtP5x10dJARQaGlpuzMOHD7UKwwYNGmjtL9l3//59KJVKpKSkwMzMDN7e3k89bs+ePcvcr1QqdTuBCly9ehXnzp0rt0h78oeIFZ0X8M/r7+XlVaotLy8vnD59WufcLCwsSuVVq1Yt8VjPIjs7GwBga2tbbsy8efPQv39/NGnSBC1btkTv3r0xYsQIrWEaT+Ph4aFzrJmZWan3aJMmTQCg1Dj1qnTnzh3k5uaiadOmpfY1b94cGo0GN2/eRIsWLcTtT3sfENE/WAATUYXkcjk6duyIjh07okmTJhg9ejS2bNmCOXPmQKPRQCKRYM+ePZBKpaWeW5lJBB6/gvW4J39kVXJ195NPPkHbtm3LfM6Txy8rRwBaP2h6mpLjfvvtt3B2di61vypuY6XRaBAQEIDp06eXub+kACtRFeelq/KOVRUuXLgAoOxCvYSfnx9SUlLw008/IS4uDmvWrMGSJUuwevVqjBkzRqfjWFpaVkm+JXR9z1a35/k+IKrpWAATkc46dOgAAEhPTwcAeHp6QhAEeHh4lCrKHufu7g6g+Mrm41dOVSoVUlNT0aZNG3FbyVWrBw8eaLXx5J9xPT09ARRfcfX396/kGWnz9PSERqPBpUuXyi2qS47r6OhYZcct6xjZ2dlV1n7J63/t2rVS+57cVl4xV93UajU2btwIKysrdOnSpcJYBwcHjB49GqNHj0Z2djb8/PwQFRUlFsBVeQ4ajQbXr1/Xen//9ttvACD+2FHX96w+udWtWxdWVla4cuVKqX2//vorzMzMKv3jUSLibdCIqAwHDhwo86rR7t27AUD8s+zAgQMhlUoxd+7cUvGCIODu3bsAigvnunXrYvXq1SgsLBRj1q1bV6poKCkwHx/nqlar8eWXX2rF+fj4wNPTE59++qn4p/PHVeb2TyEhITAzM8O8efNKjR8uOb+goCAolUp89NFHUKlUVXLcJ73xxhtISkpCbGxsqX0PHjxAUVGRXu25urqiZcuW+Oabb7Req4MHD+L8+fNasVZWVuJxnhe1Wo133nkHly9fxjvvvFPhMJKS91QJGxsbeHl5oaCgQNxmbW0NoOrOYfny5eKyIAhYvnw5ZDIZevXqBaD4fzCkUmmpsdkrV64s1ZauuUmlUgQGBuKnn37SGmqRmZmJjRs3okuXLlUy3IbIVPEKMBGVMmnSJOTm5mLAgAFo1qwZCgsLcezYMWzevBkNGzbE6NGjARQXqwsWLEBkZCRu3LiBkJAQ2NraIjU1Fdu2bcO4ceMwdepUyGQyLFiwAG+//TZ69uyJwYMHIzU1FWvXri01vrJFixbo3LkzIiMjce/ePTg4OGDTpk2lij4zMzOsWbMGffr0QYsWLTB69GjUq1cPf/75Jw4cOAClUon//e9/ep23l5cX/v3vf2P+/Pno2rUrBg4cCIVCgRMnTsDV1RXR0dFQKpVYtWoVRowYgfbt22PIkCGoW7cu0tLSsGvXLrzyyitaBVN5/vvf/+LXX38ttT00NBTTpk3Djh078Oqrr2LUqFHw8fFBTk4Ozp8/jx9//BE3btxAnTp19Dq3jz76CP3798crr7yC0aNH4/79+1i+fDlatmypVRRbWlrC29sbmzdvRpMmTeDg4ICWLVs+9XZ4unr48CG+++47AMW3eyuZCS4lJQVDhgzB/PnzK3y+t7c3unfvDh8fHzg4OODkyZP48ccftX6o5uPjAwB45513EBQUBKlUiiFDhlQqXwsLC+zduxehoaHo1KkT9uzZg127duGDDz4Qx0Lb2dnh9ddfx+effw6JRAJPT0/s3LmzzElj9MltwYIFiI+PR5cuXfB///d/MDc3xxdffIGCggLExMRU6nyI6G+Guv0EERmvPXv2CG+99ZbQrFkzwcbGRpDL5YKXl5cwadIkITMzs1T8f//7X6FLly6CtbW1YG1tLTRr1kwIDw8Xrly5ohW3cuVKwcPDQ1AoFEKHDh2EQ4cOCd26ddO6DZogCEJKSorg7+8vKBQKwcnJSfjggw+E+Pj4Mm81debMGWHgwIFC7dq1BYVCIbi7uwtvvPGGkJCQIMaU3Aat5LZVJcq75drXX38ttGvXTlAoFEKtWrWEbt26CfHx8VoxBw4cEIKCggQ7OzvBwsJC8PT0FEaNGiWcPHmywte25JZZ5T0OHz4sCELx7dYiIyMFLy8vQS6XC3Xq1BFefvll4dNPPxVvR1dym61PPvmk1HFQxq3MNm3aJDRr1kxQKBRCy5YthR07dgiDBg0SmjVrphV37NgxwcfHR5DL5VrthIaGCtbW1qWOVfL6Pk23bt20ztXGxkZo3Lix8OabbwpxcXFlPufJ26AtWLBAeOmllwR7e3vB0tJSaNasmfDhhx9q3aKvqKhImDRpklC3bl1BIpGIuVX0epV3GzRra2shJSVFCAwMFKysrAQnJydhzpw5pW6Td+fOHWHQoEGClZWVUKtWLeHtt98WLly4UKrN8nIThLL77PTp00JQUJBgY2MjWFlZCT169BCOHTumFVPyPj5x4oTW9vJuz0ZEgiARBI6OJyLDKZkF7slZtOj5aNu2LerWrSvOpEZEZAo4BpiIyASoVKpSw0gSExNx9uxZramoiYhMAccAExGZgD///BP+/v5488034erqil9//RWrV6+Gs7NzqYktiIhedCyAiYhMQK1ateDj44M1a9bgzp07sLa2RnBwMD7++GPUrl3b0OkRET1XHANMRERERCaFY4CJiIiIyKSwACYiIiIik8IxwDrQaDS4desWbG1tDTZNKBERERGVTxAEPHr0CK6urjAzq/gaLwtgHdy6dYtzrhMRERHVADdv3kT9+vUrjGEBrANbW1sAxS/ok3Ovq1QqxMXFITAwEDKZzBDpkR7YXzUP+6xmYX/VLOyvmod9Vr6srCy4ubmJdVtFWADroGTYg1KpLLMAtrKyglKp5BuxBmB/1Sy5uUDnzgKys4PRt68llEoj7rPcXKBjx+LlEycAKyvD5mMg/IzVLOyvmod99nS6DFdlAUxERksQgMuXJQCUEASVodOpmCAAly79s0xEREaLd4EgIiIiIpPCApiIiIiITAqHQBAREZHBCYKAoqIiqNVqQ6di1FQqFczNzZGfn2+Sr5VMJoNUKn3mdlgAExERkUEVFhYiPT0dubm5hk7F6AmCAGdnZ9y8edMk5yaQSCSoX78+bGxsnqkdFsBERERkMBqNBqmpqZBKpXB1dYVcLjfJwk5XGo0G2dnZsLGxeepkDy8aQRBw584d/PHHH2jcuPEzXQlmAUxERksiAdzdBeTm5kEiMfLb/RQn+88yEemksLAQGo0Gbm5usDLR2wfqQ6PRoLCwEBYWFiZXAANA3bp1cePGDahUKhbARPRisrICrl4twu7d8bCy6mvodCpmZQXcuGHoLIhqLFMs5kh/VfXXAb7biIiIiMiksAAmIiIiIpPCApiIjFZeHuDrK8XUqX7IyzN0Nk+Rl1c8FXLHjjD+ZInoRTZq1CiEhIQYOg2jZjRjgD/++GNERkbi3XffxdKlSwEA+fn5eO+997Bp0yYUFBQgKCgIK1euhJOTk/i8tLQ0TJgwAQcOHICNjQ1CQ0MRHR0Nc/N/Ti0xMRERERG4ePEi3NzcMHPmTIwaNeo5nyE9aUvKQ51jX/e0q8ZMyFhpNMCpU2YAakGjMfKpkDUa4OTJf5aJ6Jno829EVajMvzOjRo3CgwcPsH379qpPSAc3btyAh4cHzpw5g7Zt2xokh5rKKK4AnzhxAl988QVat26ttX3KlCn43//+hy1btuDgwYO4desWBg4cKO5Xq9UIDg5GYWEhjh07hvXr12PdunWYPXu2GJOamorg4GD06NEDycnJmDx5MsaMGYPY2Njndn5EREREZDwMXgBnZ2dj+PDh+M9//oNatWqJ2x8+fIivvvoKixcvRs+ePeHj44O1a9fi2LFjOH78OAAgLi4Oly5dwnfffYe2bduiT58+mD9/PlasWIHCwkIAwOrVq+Hh4YFFixahefPmmDhxIl577TUsWbLEIOdLREREL74LFy6gT58+sLGxgZOTE0aMGIG//vpL3N+9e3e88847mD59OhwcHODs7IyoqCitNn799Vd06dIFFhYW8Pb2xr59+yCVSrFr1y4AgIeHBwCgXbt2kEgk6N69u9bzP/30U7i4uKB27doIDw+HSvXPX9JWrlyJxo0bw8LCAk5OTnjttdeq54UwUgYfAhEeHo7g4GD4+/tjwYIF4vZTp05BpVLB399f3NasWTM0aNAASUlJ6Ny5M5KSktCqVSutIRFBQUGYMGECLl68iHbt2iEpKUmrjZKYyZMnl5tTQUEBCgoKxPWsrCwAxdMPPv7mKdn2+H9JD+oinUOr6vVlf9Usxd0k+3tZBaPuNpUKMnFRBeNOtvrwM1azGEN/qVQqCIIAjUYDjQGHD1Xm2IIgiLk/7sGDB+jZsyfCwsKwaNEi5OXl4f3338cbb7yBffv2iXHr16/HlClTkJSUhKSkJLz11lvw9fVFQEAA1Go1QkJC4ObmhqSkJDx69AjTpk3TOvbx48fRuXNnxMXFoUWLFpDL5dBoNBAEAQcOHICzszMSEhJw7do1DB06FK1bt8bYsWNx8uRJvPPOO1i/fj1efvll3Lt3D0eOHDHo66+rkvMr6z7A+ryPDVoAb9q0CadPn8aJEydK7cvIyIBcLoe9vb3WdicnJ2RkZIgxjxe/JftL9lUUk5WVhby8PFhaWpY6dnR0NObOnVtqe1xcXLk36Y6Pjy/nLKk8cj1id1+u2mOzv2qG/HwpgFcBAPv374eFhfHOey/Nz/87UyA2NhZqCwuD5mNo/IzVLIbsL3Nzczg7OyM7O1v86y0AFKme7+e95GKXPlQqFYqKiko9d/HixWjVqhVmzJghblu6dClatmyJ06dPw8vLC0VFRfD29hYvyIWEhODzzz/Hnj170KlTJ+zbtw8pKSn46aefxDomMjISAwYMAAA8evRIrGEsLCzE+iQrKwsqlQp2dnb48MMPxRn2AgMDERsbi8GDB+PKlSuwsrKCn58fbG1tUatWLXh6elbqNXjeCgsLkZeXh0OHDqGoSPtCmj5TaRusAL558ybeffddxMfHw8LI/qGIjIxERESEuJ6VlQU3NzcEBgZCqVRqxapUKsTHxyMgIAAymZHPVGVktqfq/kEL8VA+PUgH7K+aJSfnn+WePXvC3t6I++yxZIOCggBrawMmYzj8jNUsxtBf+fn5uHnzJmxsbLTqAfO7j55rHkqlrd7PkclkMDc3L1Ub/Prrrzh8+DDq169f6jmZmZlo3749zM3N0bp1a63n1qtXDw8fPoRSqcQff/wBNzc3NG7cWNz/+BAHW1tb2NjYAACsra212pHJZGjZsqXW0FI3NzdcuHABSqUS//rXv/DJJ5+gffv2CAoKQlBQEAYMGFAjZuLLz8+HpaUl/Pz8StWP+hTwBiuAT506hdu3b6N9+/biNrVajUOHDmH58uWIjY1FYWEhHjx4oHUVODMzE87OzgAAZ2dn/PLLL1rtZmZmivtK/luy7fEYpVJZ5tVfAFAoFFAoFKW2y2Sycr8gKtpH5ZDq/var6teW/VUzyGRAnToCCgsLjb/PipP9e1FWvG7CjL6/SIsh+0utVkMikcDMzMygs8FV5tgSiUTM/XE5OTno168fFi5cWOo5Li4uYrxcLtd6rpmZGQRBgJmZmTjj2ZP7Hz92yfqTr51EIimzbY1GAzMzM9jZ2eH06dNITExEXFwcoqKiMG/ePJw4caLUX96NTclrU9Z7Vp/3sMHeab169cL58+eRnJwsPjp06IDhw4eLyzKZDAkJCeJzrly5grS0NPj6+gIAfH19cf78edy+fVuMiY+Ph1KphLe3txjzeBslMSVtEJHxsrYGbt0qwjff7DX+C6rW1sCdO8UPo0+WiKpT+/btcfHiRTRs2BBeXl5aD2sdvx+aNm2Kmzdval3Ee3LIqFxePJhQrdZ/uIi5uTn8/f0RExODc+fO4caNG9i/f7/e7dRUBrsCbGtri5YtW2pts7a2Ru3atcXtYWFhiIiIgIODA5RKJSZNmgRfX1907twZABAYGAhvb2+MGDECMTExyMjIwMyZMxEeHi5ewR0/fjyWL1+O6dOn46233sL+/fvxww8/iL+gJCIiIqqshw8fIjk5WWvbuHHj8J///AdDhw4V7/Jw7do1bNq0CWvWrCn1462yBAQEwNPTE6GhoYiJicGjR48wc+ZMABCvDjs6OsLS0hJ79+5F/fr1YWFhATu7p9/PeOfOnbh+/Tr8/PxQq1Yt7N69GxqNBk2bNtX/BaihDH4XiIosWbIEZmZmGDRokNZEGCWkUil27tyJCRMmwNfXF9bW1ggNDcW8efPEGA8PD+zatQtTpkzBsmXLUL9+faxZs6Z4jB4REREZpZoyAVJiYiLatWuntS0sLAxHjx7FjBkzEBgYiIKCAri7u6N37946D7WQSqXYvn07xowZg44dO6JRo0b45JNP0K9fP/Ein7m5OT777DPMmzcPs2fPRteuXZGYmPjUtu3t7bF161ZERUUhPz8fjRs3xvfff48WLVroff41lUQQBMHQSRi7rKws2NnZiQPTH6dSqbB792707duX4930ZIiZ4NhfNUteHtC7twZ3797DsWN2UCqNuM/y8oA+fYqX9+wByvmNwYuOn7GaxRj6Kz8/H6mpqfDw8DC6H8Ubm6NHj6JLly44ffo02rRpY9Ax04ZS0fulonrtSUZ9BZiITJtGAxw6ZAagTs2YCvngwX+WiYie0bZt22BjY4PGjRvj2rVrePfdd/HKK6+IE2BQ5bEAJiIiIjJCjx49wowZM5CWloY6derA398fn3zyiaHTeiGwACYiIiIyQiNHjsTIkSO1tmk0mhoxYYWxM73BI0RERERk0lgAExEREZFJYQFMRERERCaFY4CJyKhZWQmVmuXIIKysDJ0BERHpgFeAichoWVsDDx4UYfPmXcY/u7C1NZCTU/ww+mSJiEwbC2AiIiIiMiksgImIiIioWkRFRaFt27bi+qhRoxASEmKwfEqwACYio5WfD/TvL8X8+Z2Qn2/obJ4iPx8IDi5+GH2yRPSsHj16hMmTJ8Pd3R2WlpZ4+eWXceLECa0YiURS5qOiySxGjRolxsnlcnh5eWHevHkoKiqq7lN6ZhKJBNu3b9faNnXqVCQkJBgmoQrwR3BEZLTUamDPHjMAzlCrjXwqZLUa2L37n2UieqGNGTMGFy5cwLfffgtXV1d899138Pf3x6VLl1CvXj0AQHp6utZz9uzZg7CwMAwaNKjCtnv37o21a9eioKAAu3fvRnh4OGQyGSIjI/XOU61WQyKRwMzMMNc8bWxsYGNjY5BjV4RXgImIiMjolPymtKzHk39kqSg2L0+3WH3k5eXhv//9L2JiYuDn5wcvLy9ERUXBy8sLq1atEuOcnZ21Hj/99BN69OiBRo0aVdi+QqGAs7Mz3N3dMWHCBPj7+2PHjh0AgIKCAsyaNQtubm6wtrZGp06dkJiYKD533bp1sLe3x44dO+Dt7Q2FQoG0tDQUFBRgxowZcHNzg0KhgJeXF7766ivxeRcuXECfPn1gY2MDJycnjBgxAn/99Ze4v3v37njnnXcwffp0ODg4wNnZGVFRUeL+hg0bAgAGDBgAiUQirj85BOJJGo0G0dHR8PDwgKWlJdq0aYMff/zxKT3w7FgAExERkdGxsSn/8eQFVEfH8mP79NGObdiw7Dh9FBUVQa1Ww8LCQmu7paUljhw5UuZzMjMzsWvXLoSFhel3sL/bLSwsBABMmjQJv/zyCzZu3Ihz587h9ddfR+/evXH16lUxPjc3FwsXLsSaNWtw8eJFODo6YuTIkfj+++/x2Wef4fLly/jiiy/EK7MPHjxAz5490a5dO5w8eRJ79+5FZmYm3njjDa081q9fD2tra/z888+IiYnBvHnzEB8fDwDi8I+1a9ciPT291HCQ8kRHR+Obb77B6tWrcfHiRUyZMgVvvvkmDh48qPfrpA8OgSAiIiLSg62tLXx9fTF//nw0b94cTk5O+P7775GUlAQvL68yn7N+/XrY2tpi4MCBOh9HEAQkJCQgNjYWkyZNQlpaGtatW4fz58+jadOmMDMzw9SpU7F3716sXbsWH330EQBApVJh5cqVaNOmDQDgt99+ww8//ID4+Hj4+/sDgNZV6OXLl6Ndu3bi8wHg66+/hpubG3777Tc0adIEANC6dWvMmTMHANC4cWMsX74cCQkJCAgIQN26dQEA9vb2cHZ21un8CgoK8NFHH2Hfvn3w9fUV8zpy5Ai++OILdOvWTefXSl8sgImIiMjoZGeXv08q1V6/fbv82CeHvt64UemUtHz77bd46623UK9ePUilUrRv3x5Dhw7FqVOnyoz/+uuvMXz48FJXjcuyc+dO2NjYQKVSQaPRYNiwYYiKikJiYiLUajU6duyoFV9QUIDatWuL63K5HK1btxbXk5OTIZVKyy0oz549iwMHDpQ5VjclJUWrAH6ci4sLblf04j/FtWvXkJubi4CAAK3thYWFaNeuXaXb1QULYCIiIjI6+swnU12xFfH09MTBgweRk5ODrKwsuLi4YPDgwWWO7z18+DCuXLmCzZs369R2jx49sGrVKsjlcri6usLcvLhcy87OhlQqxYEDB2BnZ6f1w7bHi1dLS0tIJBKt9YpkZ2ejX79+WLhwYal9Li4u4rJMJtPaJ5FIoNFodDqn8o4LALt27RJ/OFhCoVBUul1dsAAmIiIiqiRra2tYW1vj/v37iI2NRUxMTKmYr776Cj4+PuKQBF3aLGsoRbt27aBWq3Hnzh34+PjofGeHVq1aQaPR4ODBg+IQiMe1b98e//3vf9GwYUOx2K4MmUym19T1j/9IrzqHO5SFP4IjIqNlbQ0UFqqwfftPxj+7sLU1IAjFD6NPloieVWxsLPbu3YvU1FTEx8ejR48eaNasGUaPHq0Vl5WVhS1btmDMmDHPfMwmTZpg2LBhmDBhArZu3YrU1FT88ssviI6Oxq5du8p9XsOGDREaGoq33noL27dvR2pqKhITE/HDDz8AAMLDw3Hv3j0MHToUJ06cQEpKCmJjYzF69Gi9CtqGDRsiISEBGRkZuH///lPjbW1tMXXqVEyZMgXr169HSkoKTp8+jc8//xzr16/X+biVwQKYiIiISE8PHz5EeHg4mjVrhpEjR6JLly6IjY0tNUxg06ZNEAQBQ4cOrZLjfv311xgyZAimTZuGpk2bIiQkBCdOnECDBg0qfN6qVavw2muv4f/+7//QrFkzjB07Fjl/3//N1dUVR48ehVqtRmBgIFq1aoXJkyfD3t5er/sHL1q0CPHx8XBzc9N5DO/8+fMxa9YsREdHo3nz5ujduzd27doFDw8PnY9bGRJBEIRqPcILICsrC3Z2dnj48CGUSqXWPpVKhd27d6Nv376l3vRUsS0pD3WOfd3TrkqOyf6qedhnNQv7q2Yxhv7Kz89HamoqPDw8dPqBmKnTaDTIysqCUqk02OQWhlTR+6Wieu1JHANMREYrPx8YPlyKjIwO6NkTMOp6Kj8fGDGiePnbbwH+Q05EZLRYABOR0VKrga1bzQDUqxlTIZfMXrRunUFTISKiipnetXMiIiIiMmksgImIiIjIpBi0AF61ahVat24NpVIJpVIJX19f7NmzR9zfvXt3SCQSrcf48eO12khLS0NwcDCsrKzg6OiIadOmoaioSCsmMTER7du3h0KhgJeXF9bxz5NEREREJsugY4Dr16+Pjz/+GI0bN4YgCFi/fj369++PM2fOoEWLFgCAsWPHYt68eeJzrKysxGW1Wo3g4GA4Ozvj2LFjSE9Px8iRIyGTycT5rFNTUxEcHIzx48djw4YNSEhIwJgxY+Di4oKgoKDne8JEREREZHAGLYD79euntf7hhx9i1apVOH78uFgAW1lZwdnZucznx8XF4dKlS9i3bx+cnJzQtm1bzJ8/HzNmzEBUVBTkcjlWr14NDw8PLFq0CADQvHlzHDlyBEuWLGEBTERERGSCjOYuEGq1Glu2bEFOTg58fX3F7Rs2bMB3330HZ2dn9OvXD7NmzRKvAiclJaFVq1ZwcnIS44OCgjBhwgRcvHgR7dq1Q1JSUqlp/4KCgjB58uRycykoKEBBQYG4npWVBaD4fokqlfYv0UvWn9xOOlAXPT3mb1X1+rK/apbibpL9vayCUXebSgWZuKiCcSdbffgZq1mMob9UKhUEQYBGo4FGozFYHjVFyfQNJa+ZqdFoNBAEASqVClKpVGufPu9jgxfA58+fh6+vL/Lz82FjY4Nt27bB29sbADBs2DC4u7vD1dUV586dw4wZM3DlyhVs3boVAJCRkaFV/AIQ1zMyMiqMycrKQl5eHiwtLUvlFB0djblz55baHhcXpzUE43Hx8fF6njnJ9Yjdfblqj83+qhkEAdi0qfgL7uhRNSQSAydUEUGAdNMmAIA6MRHGnWz142esZjFkf5mbm8PZ2RnZ2dkoLCw0WB41zaNHjwydgkEUFhYiLy8Phw4dKvWbr9zcXJ3bMXgB3LRpUyQnJ+Phw4f48ccfERoaioMHD8Lb2xvjxo0T41q1agUXFxf06tULKSkp8PT0rLacIiMjERERIa5nZWXBzc0NgYGBZc4EFx8fj4CAgBdy1qPtqVl6xYd4VDzzSmXb1qfdirzo/fUiYp/VLOyvmsUY+is/Px83b96EjY0NZ4LTgSAIePToEWxtbSGpAf+jvW7dOkRERODevXsAgLlz5+Knn37C6dOnK9Vefn4+LC0t4efnV+ZMcLoyeAEsl8vh5eUFAPDx8cGJEyewbNkyfPHFF6ViO3XqBAC4du0aPD094ezsjF9++UUrJjMzEwDEccPOzs7itsdjlEplmVd/AUChUEChUJTaLpPJyv2CqGhfjSbV7y2i12ugR9tV/dq+sP31AmOf1Szsr5rFkP2lVqshkUhgZmZWo6b2ffToEWbNmoVt27bh9u3baNeuHZYtW4aOHTuKMZmZmZgxYwbi4uLw4MED+Pn54fPPP0fjxo3LbTcqKkr8K7RUKkX9+vUxYMAAzJ8/HzY2NuKwh5LXzJg0bNgQkydP1hpmOnToULz66qtiriVFe2VzNzMzg0QiKfM9q8972LheORSP7Xh8/O3jkpOTAQAuLi4AAF9fX5w/fx63b98WY+Lj46FUKsVhFL6+vkhISNBqJz4+XmucMREZp4ICICxMimXL2qGcrwXjUVAAjBpV/DD6ZInoWY0ZMwbx8fH49ttvcf78eQQGBsLf3x9//vkngOIrtSEhIbh+/Tp++uknnDlzBu7u7vD390dOTk6Fbbdo0QLp6em4ceMGFi5ciC+//BLvvfdepfIUBKHUUIHnydLSEo6OjgY7fnkMWgBHRkbi0KFDuHHjBs6fP4/IyEgkJiZi+PDhSElJwfz583Hq1CncuHEDO3bswMiRI+Hn54fWrVsDAAIDA+Ht7Y0RI0bg7NmziI2NxcyZMxEeHi5ewR0/fjyuX7+O6dOn49dff8XKlSvxww8/YMqUKYY8dSLSQVER8O23ZjhwoAEM+P2tm6IiYP364ofRJ0tUA+TklP/Iz9c9Ni9Pt1g95OXl4b///S9iYmLg5+cHLy8vREVFwcvLC6tWrQIAXL16FcePH8eqVavQsWNHNG3aFKtWrUJeXh6+//77CtsvGRddv359DB48GMOHD8eOHTsAFF8oXLx4MTw9PWFpaYk2bdrgx5Jp2FE894FEIsGePXvg4+MDhUKBI0eOQKPRICYmBl5eXlAoFGjQoAE+/PBD8Xk3b97EG2+8AXt7ezg4OKB///64ceOGuH/UqFEICQnBp59+ChcXF9SuXRvh4eHiD8+6d++O33//HVOmTBHnbgCKh0DY29tXeL5r1qxB8+bNYWFhgWbNmmHlypU690VlGXQIxO3btzFy5Eikp6fDzs4OrVu3RmxsLAICAnDz5k3s27cPS5cuRU5ODtzc3DBo0CDMnDlTfL5UKsXOnTsxYcIE+Pr6wtraGqGhoVr3Dfbw8MCuXbswZcoULFu2DPXr18eaNWt4CzQiIiJjZmNT/r6+fYFdu/5Zd3QEyvsBVLduQGLiP+sNGwJ//VU67u+7K+iiqKgIarW61BhUS0tLHDlyBADEv2Y/HmNmZiYWpGPGjNH5eJaWluIPBD/++GNs3rwZK1euRNOmTXHo0CG8+eabqFu3Lrp16yY+5/3338enn36KRo0aoVatWoiMjMR//vMfLFmyBF26dEF6ejp+/fVXAMVjwYOCguDr64vDhw/D3NwcCxYsQO/evXHu3DnI5cU/Wz9w4ABcXFxw4MABXLt2DYMHD0bbtm0xduxYbN26FW3atMG4ceMwduxYnc9tw4YNmD17NpYvX4527drhzJkzGDt2rFjTVReDFsBfffVVufvc3Nxw8ODBp7bh7u6O3bt3VxjTvXt3nDlzRu/8iIiIiJ5ka2sLX19fzJ8/H82bN4eTkxO+//57JCUlib9ratasGRo0aIDIyEh88cUXsLa2xpIlS/DHH38gPT1d52OdOnUKGzduRM+ePVFQUIDo6Ghs27YN/v7+MDMzQ6NGjXDkyBF88cUXWgXwvHnzEBAQAKB4vPKyZcuwfPlysaj09PREly5dAACbN2+GRqPBmjVrxCu3a9euhb29PRITExEYGAgAqFWrFpYvXw6pVIpmzZohODgYCQkJGDt2LBwcHCCVSmFra1vu/A1lmTNnDhYtWoSBAwcCKL5weenSJXzxxRcvbgFMREREVKbs7PL3PXH/Vzz2W6BSnvyx1WN/1n8W3377Ld566y3Uq1cPUqkU7du3x9ChQ3Hq1CkAxT/I2rp1K8LCwsTi0N/fH3369BHv5Vue8+fPw8bGBmq1GoWFhQgODsby5ctx7do15ObmisViicLCQrRr105rW4cOHcTly5cvo6CgAL169SrzeGfPnsW1a9dga2urtT0/Px8pKSnieosWLbTuvevi4oLz589XeC4VycnJQUpKCsLCwrSuGhcVFcHOzq7S7eqCBTAREREZH2trw8dWwNPTEwcPHkROTg6ysrLg4uKCwYMHo1GjRmKMj4+PeKvXwsJC1K1bF506ddIqTsvStGlT7NixA+bm5nB1dRWHIJSMyd28eTMaN26sdSeFJ+9eZf3YeZZ316sS2dnZ8PHxwYYNG0rtq1u3rrj85F0WJBLJM03Gkf33/+T85z//Ee/0VeLJSS6qGgtgIiIiokqytraGtbU17t+/j9jYWMTExJSKKbmaefXqVZw8eRLz58+vsM3HbxH7OG9vbygUCty8eRN9+vTR+VZijRs3hqWlJRISEsoce9y+fXts3rwZjo6OpeY70IdcLodardY53snJCa6urrh+/TqGDx9e6eNWBgtgIiIiIj3FxsZCEAQ0bdoU165dw7Rp09CsWTOMHj1ajNmyZQvq1q2LBg0a4Pz583j33XcREhIijqnVl62tLd577z38+9//hkKhgJ+fHx4+fIijR49CqVSWO2bWwsICM2bMwPTp0yGXy/HKK6/gzp07uHjxIsLCwjB8+HB88skn6N+/P+bNm4f69evj999/x9atWzF9+nTUr19fp/waNmyIQ4cOYciQIVAoFKhTp85TnzN37ly88847sLOzQ+/evVFQUICTJ0/i/v37WpOSVTUWwERktKysgD//VGHfvn2wsvI3dDoVs7L6ZxxiOVOmE9GL4+HDh4iMjMQff/wBBwcHDBo0CB9++KHWMIH09HREREQgMzMTLi4uGDlyJGbNmvVMx503bx5sbW2xcOFCvP3227C3t0f79u3xwQcfVPi8WbNmwdzcHLNnz8atW7fg4uKC8ePHAwCsrKxw6NAhzJgxAwMHDsSjR49Qr1499OrVS68rwvPmzcPbb78NT09PFBQUPHWsM1B8P2UrKyt88sknmDZtGqytrdGqVSutyTSqg0TQJTsTl5WVBTs7Ozx8+LDMqZB3796Nvn37vpCzHm1JeahX/Oueug9a16dtfdqtyIveXy8i9lnNwv6qWYyhv/Lz85GamgoPDw9OhawDjUaDrKwsKJVKo5sJ7nmo6P1SUb32JNN75YiIiIjIpHEIBL1wKryyrC6CHMD21CxAWvz2r6qry1T1CgqAyZPN8PvvrdGrF2DUFxQLCoCS8WqLFwNP/CKbiIiMBwtgIjJaRUXA6tVSAB4oKlIZOp2KFRUBJdN3xsSwACYiMmIcAkFEREREJoUFMBERERkcf5NPuqiq9wkLYCIiIjKYkrtP5ObmGjgTqgkKCwsBPPtMcRwDTERERAYjlUphb2+P23/fR9vKygoSicTAWRkvjUaDwsJC5Ofnm9xt0DQaDe7cuQMrKyuYmz9bCcsCmIiIiAzK2dkZAMQimMonCALy8vJgaWlpkv+jYGZmhgYNGjzzubMAJiIiIoOSSCRwcXGBo6MjVCojv+OLgalUKhw6dAh+fn4mOdmMXC6vkivfLICJyGhZWgK//abCgQMHYGnZw9DpVMzSEkhN/WeZiPQmlUqfeWzni04qlaKoqAgWFhYmWQBXFRbARGS0zMyAhg0BJ6c8GP1Qt5JkiYjI6Bn7PylERERERFWKBTARGa3CQuD9982wbp03/r7zjfEqLASmTSt+GH2yRESmjUMgiMhoqVTA4sVSAI2N/4cxKhXw6afFy1FRgFxu0HSIiKh8vAJMRERERCaFBTARERERmRQWwERERERkUlgAExEREZFJYQFMRERERCbFoAXwqlWr0Lp1ayiVSiiVSvj6+mLPnj3i/vz8fISHh6N27dqwsbHBoEGDkJmZqdVGWloagoODYWVlBUdHR0ybNg1FRUVaMYmJiWjfvj0UCgW8vLywbt2653F6RERERGSEDFoA169fHx9//DFOnTqFkydPomfPnujfvz8uXrwIAJgyZQr+97//YcuWLTh48CBu3bqFgQMHis9Xq9UIDg5GYWEhjh07hvXr12PdunWYPXu2GJOamorg4GD06NEDycnJmDx5MsaMGYPY2Njnfr5EpB9LS+DMGRU++2y/8c8ubGkJXLhQ/DD6ZImITJtB7wPcr18/rfUPP/wQq1atwvHjx1G/fn189dVX2LhxI3r27AkAWLt2LZo3b47jx4+jc+fOiIuLw6VLl7Bv3z44OTmhbdu2mD9/PmbMmIGoqCjI5XKsXr0aHh4eWLRoEQCgefPmOHLkCJYsWYKgoKDnfs5EpDszM6BFC+D33x/VjKmQW7QwdBZERKQDo5kIQ61WY8uWLcjJyYGvry9OnToFlUoFf39/MaZZs2Zo0KABkpKS0LlzZyQlJaFVq1ZwcnISY4KCgjBhwgRcvHgR7dq1Q1JSklYbJTGTJ08uN5eCggIUFBSI61lZWQAAlUpV6mb8JetGf5P+ylIXPT3mMXq9Dnq0XWXtlux7LOaF7bsXxAv/GXvBsL9qFvZXzcM+K58+r4nBC+Dz58/D19cX+fn5sLGxwbZt2+Dt7Y3k5GTI5XLY29trxTs5OSEjIwMAkJGRoVX8luwv2VdRTFZWFvLy8mBZxp8qo6OjMXfu3FLb4+LiYGVlVeZ5xMfH63bCNYy+c1ntvlw9bVd1u/LfjleqbXq+VCoJfvyxCYCmUKn2QSYTDJ1SuSQqFZr8+CMA4LfXXoMgkxk4I8N6Ub8TX1Tsr5qHfVZabm6uzrEGL4CbNm2K5ORkPHz4ED/++CNCQ0Nx8OBBg+YUGRmJiIgIcT0rKwtubm4IDAyEUqnUilWpVIiPj0dAQABkL+A/eNtTs/SKD/FQPj2oEm1XWbvqIsh/O47CJp0BqbnebdPzlZMDvP568efq888bwN7eiD9jOTmQvf46AMBz9WrA2trACRnGi/6d+KJhf9U87LPylfzFXhcGL4Dlcjm8vLwAAD4+Pjhx4gSWLVuGwYMHo7CwEA8ePNC6CpyZmQlnZ2cAgLOzM3755Ret9kruEvF4zJN3jsjMzIRSqSzz6i8AKBQKKBSKUttlMlm5b7aK9tVoUv3eInq9Bnq0XeXtSs3FuBey314Qj3eN0X/GHstNJpNpJ2+CjL6/SAv7q+Zhn5Wmz+thdD8r0Wg0KCgogI+PD2QyGRISEsR9V65cQVpaGnx9fQEAvr6+OH/+PG7fvi3GxMfHQ6lUwtvbW4x5vI2SmJI2iIiIiMi0GPQKcGRkJPr06YMGDRrg0aNH2LhxIxITExEbGws7OzuEhYUhIiICDg4OUCqVmDRpEnx9fdG5c2cAQGBgILy9vTFixAjExMQgIyMDM2fORHh4uHgFd/z48Vi+fDmmT5+Ot956C/v378cPP/yAXbt2GfLUiYiIiMhADFoA3759GyNHjkR6ejrs7OzQunVrxMbGIiAgAACwZMkSmJmZYdCgQSgoKEBQUBBWrlwpPl8qlWLnzp2YMGECfH19YW1tjdDQUMybN0+M8fDwwK5duzBlyhQsW7YM9evXx5o1a3gLNCIiIiITZdAC+Kuvvqpwv4WFBVasWIEVK1aUG+Pu7o7du3dX2E737t1x5syZSuVIRERERC8WoxsDTERERERUnQx+FwgiovJYWADHjhXh6NGjsLB42dDpVMzCAii5K42FhWFzISKiCrEAJiKjJZUCHToIuH37AaRSQ2fzFFIp0LGjobMgIiIdcAgEEREREZkUFsBEZLQKC4FFi8ywbZsXCgsNnc1TFBYCn3xS/DD6ZImITBsLYCIyWioVEBkpxfr1LaBSGTqbp1CpgOnTix9GnywRkWljAUxEREREJoUFMBERERGZFBbARERERGRSWAATERERkUlhAUxEREREJoUFMBERERGZFM4ER0RGy8ICiI8vwvHjx2Fh0cnQ6VTMwgI4cOCfZSIiMlosgInIaEmlQLduAnJy7taMqZC7dzd0FkREpAMOgSAiIiIik8ICmIiMlkoFrFplht27PYx/cjWVClixovhh9MkSEZk2FsBEZLQKC4F335Xiyy9bo7DQ0Nk8RWEhMHFi8cPokyUiMm0sgImIiIjIpLAAJiIiIiKTwgKYiIiIiEwKC2AiIiIiMiksgImIiIjIpLAAJiIiIiKTwpngiMhoKRTA9u1FOHnyJBQKH0OnUzGFAti5859lIiIyWpUqgK9fv45GjRpVdS5ERFrMzYG+fQUAmTA39v9dNzcHgoMNnQUREemgUkMgvLy80KNHD3z33XfIz8+v6pyIiIiIiKpNpQrg06dPo3Xr1oiIiICzszPefvtt/PLLL3q3Ex0djY4dO8LW1haOjo4ICQnBlStXtGK6d+8OiUSi9Rg/frxWTFpaGoKDg2FlZQVHR0dMmzYNRUVFWjGJiYlo3749FAoFvLy8sG7dOr3zJaLnS6UCvvlGgoQEN+OfXVilAtatK34YfbJERKatUgVw27ZtsWzZMty6dQtff/010tPT0aVLF7Rs2RKLFy/GnTt3dGrn4MGDCA8Px/HjxxEfHw+VSoXAwEDk5ORoxY0dOxbp6eniIyYmRtynVqsRHByMwsJCHDt2DOvXr8e6deswe/ZsMSY1NRXBwcHo0aMHkpOTMXnyZIwZMwaxsbGVOX0iek4KC4ExY8zx+eftjX924cJCYPTo4ofRJ0tEZNqe6S4Q5ubmGDhwILZs2YKFCxfi2rVrmDp1Ktzc3DBy5Eikp6dX+Py9e/di1KhRaNGiBdq0aYN169YhLS0Np06d0oqzsrKCs7Oz+FAqleK+uLg4XLp0Cd999x3atm2LPn36YP78+VixYgUK//5HaPXq1fDw8MCiRYvQvHlzTJw4Ea+99hqWLFnyLKdPRERERDXQM/2s5OTJk/j666+xadMmWFtbY+rUqQgLC8Mff/yBuXPnon///noNjXj48CEAwMHBQWv7hg0b8N1338HZ2Rn9+vXDrFmzYGVlBQBISkpCq1at4OTkJMYHBQVhwoQJuHjxItq1a4ekpCT4+/trtRkUFITJkyeXmUdBQQEKCgrE9aysLACASqWC6ok/bZasP7n9haEuenrMY/R6HfRou8raLdn3WIw+bW9PzdI5NsRD+fQgqlBx18j+XlYZ98gClervTP9+Txl1stXnhf9OfMGwv2oe9ln59HlNKlUAL168GGvXrsWVK1fQt29ffPPNN+jbty/MzIovKHt4eGDdunVo2LChzm1qNBpMnjwZr7zyClq2bCluHzZsGNzd3eHq6opz585hxowZuHLlCrZu3QoAyMjI0Cp+AYjrGRkZFcZkZWUhLy8PlpaWWvuio6Mxd+7cUjnGxcWJhfeT4uPjdT7XmkSuZ/zuy9XTdlW3K//teLW1XZl2qWz5+VIArwIA9u/fDwsLtWETqoA0P//vTIHY2FioLSwMmo+hvajfiS8q9lfNwz4rLTc3V+fYShXAq1atwltvvYVRo0bBxcWlzBhHR0d89dVXOrcZHh6OCxcu4MiRI1rbx40bJy63atUKLi4u6NWrF1JSUuDp6VmZ9J8qMjISERER4npWVhbc3NwQGBioNfwCKP6/jfj4eAQEBEAmkz3ZVI2nzxVPQL+rntV1NbXCdtVFkP92HIVNOgNS86pt+wm8AvzsHv85QM+ePWFvb8SfsceSDQoKAqytDZiM4bzo34kvGvZXzcM+K1/JX+x1UakC+OrVq0+NkcvlCA0N1am9iRMnYufOnTh06BDq169fYWynTp0AANeuXYOnpyecnZ1LDbPIzMwEADg7O4v/Ldn2eIxSqSx19RcAFAoFFGXcyF4mk5X7ZqtoX40m1e8totdroEfbVd6u1FyMM4qcqUyPv4RG/xl7LDeZTKadvAky+v4iLeyvmod9Vpo+r0elfgS3du1abNmypdT2LVu2YP369Tq3IwgCJk6ciG3btmH//v3w8PB46nOSk5MBQLzy7Ovri/Pnz+P27dtiTHx8PJRKJby9vcWYhIQErXbi4+Ph6+urc65ERERE9GKoVAEcHR2NOnXqlNru6OiIjz76SOd2wsPD8d1332Hjxo2wtbVFRkYGMjIykJeXBwBISUnB/PnzcerUKdy4cQM7duzAyJEj4efnh9atWwMAAgMD4e3tjREjRuDs2bOIjY3FzJkzER4eLl7FHT9+PK5fv47p06fj119/xcqVK/HDDz9gypQplTl9InpOFApg48YiTJt2wvhnF1YogB9+KH4YfbJERKatUkMg0tLSyrxa6+7ujrS0NJ3bWbVqFYDiyS4et3btWowaNQpyuRz79u3D0qVLkZOTAzc3NwwaNAgzZ84UY6VSKXbu3IkJEybA19cX1tbWCA0Nxbx588QYDw8P7Nq1C1OmTMGyZctQv359rFmzpnicHhEZLXNz4LXXBFhZ3YK5eVtDp1Mxc3Pg9dcNnQUREemgUgWwo6Mjzp07V+ouD2fPnkXt2rV1bkcQhAr3u7m54eDBg09tx93dHbt3764wpnv37jhz5ozOuRERERHRi6lSQyCGDh2Kd955BwcOHIBarYZarcb+/fvx7rvvYsiQIVWdIxGZqKIi4McfJTh61BVF+t2S+vkrKgK2bCl+GH2yRESmrVJXgOfPn48bN26gV69eMDcvbkKj0WDkyJF6jQEmIqpIQQEwbJg5gI744AMVyrhpi/EoKADeeKN4OTu7eEgEEREZpUp9Q8vlcmzevBnz58/H2bNnYWlpiVatWsHd3b2q8yMiIiIiqlLPdImiSZMmaNKkSVXlQkRERERU7SpVAKvVaqxbtw4JCQm4ffs2NBqN1v79+/dXSXJERERERFWtUgXwu+++i3Xr1iE4OBgtW7aERCKp6ryIiIiIiKpFpQrgTZs24YcffkDfvn2rOh8iIiIiompVqdugyeVyeHl5VXUuRERERETVrlIF8HvvvYdly5Y9dSILIqJnIZcDa9YUYdKk05DLDZ3NU8jlwNq1xQ+jT5aIyLRVagjEkSNHcODAAezZswctWrSATCbT2r9169YqSY6ITJtMBowcKWD37puQyVoZOp2KyWTAqFGGzoKIiHRQqQLY3t4eAwYMqOpciIiIiIiqXaUK4LVr11Z1HkREpRQVAbt3S3DypBMCA4svshqtoiIgNrZ4OSiIM8ERERmxSn9DFxUVITExESkpKRg2bBhsbW1x69YtKJVK2NjYVGWORGSiCgqAkBBzAJ3x3ns1YCrkV18tXuZUyERERq1S39C///47evfujbS0NBQUFCAgIAC2trZYuHAhCgoKsHr16qrOk4iIiIioSlTqLhDvvvsuOnTogPv378PysUsyAwYMQEJCQpUlR0RERERU1Sp1Bfjw4cM4duwY5E/c6qdhw4b4888/qyQxIiIiIqLqUKkrwBqNBmq1utT2P/74A7a2ts+cFBERERFRdalUARwYGIilS5eK6xKJBNnZ2ZgzZw6nRyYiIiIio1apIRCLFi1CUFAQvL29kZ+fj2HDhuHq1auoU6cOvv/++6rOkYiIiIioylSqAK5fvz7Onj2LTZs24dy5c8jOzkZYWBiGDx+u9aM4IqJnIZcDy5apcfHiRcjlzQ2dTsXkcmD58n+WiYjIaFX6RpXm5uZ48803qzIXIiItMhkwYYIGu3enQiYz8gJYJgPCww2dBRER6aBSBfA333xT4f6RI0dWKhkiIiIioupWqQL43Xff1VpXqVTIzc2FXC6HlZUVC2AiqhJqNXDwoATnz9dGUJCRT4WsVgOHDxcvd+0KSKWGzYeIiMpVqQL4/v37pbZdvXoVEyZMwLRp0545KSIiAMjPBwICzAF0wcSJKlhYGDqjCuTnAz16FC9nZwPW1obNh4iIylWp26CVpXHjxvj4449LXR0mIiIiIjImVVYAA8U/jLt165bO8dHR0ejYsSNsbW3h6OiIkJAQXLlyRSsmPz8f4eHhqF27NmxsbDBo0CBkZmZqxaSlpSE4OBhWVlZwdHTEtGnTUFRUpBWTmJiI9u3bQ6FQwMvLC+vWrav0eRIRERFRzVWpIRA7duzQWhcEAenp6Vi+fDleeeUVnds5ePAgwsPD0bFjRxQVFeGDDz5AYGAgLl26BOu//3w4ZcoU7Nq1C1u2bIGdnR0mTpyIgQMH4ujRowAAtVqN4OBgODs749ixY0hPT8fIkSMhk8nw0UcfAQBSU1MRHByM8ePHY8OGDUhISMCYMWPg4uKCoKCgyrwERERERFRDVaoADgkJ0VqXSCSoW7cuevbsiUWLFunczt69e7XW161bB0dHR5w6dQp+fn54+PAhvvrqK2zcuBE9e/YEAKxduxbNmzfH8ePH0blzZ8TFxeHSpUvYt28fnJyc0LZtW8yfPx8zZsxAVFQU5HI5Vq9eDQ8PDzG35s2b48iRI1iyZAkLYCIiIiITU6kCWKPRVHUeAICHDx8CABwcHAAAp06dgkqlgr+/vxjTrFkzNGjQAElJSejcuTOSkpLQqlUrODk5iTFBQUGYMGECLl68iHbt2iEpKUmrjZKYyZMnl5lHQUEBCgoKxPWsrCwAxXe7UKlUWrEl609uf2Goi54e8xi9Xgc92q6ydkv2PRZjFDlTmYpfQtnfyyoY9UuqUkEmLqpg3MlWnxf+O/EFw/6qedhn5dPnNan0RBhVTaPRYPLkyXjllVfQsmVLAEBGRgbkcjns7e21Yp2cnJCRkSHGPF78luwv2VdRTFZWFvLy8krNXhcdHY25c+eWyjEuLg5WVlZl5h8fH6/jmdYs+s5ntfty9bRd1e3KfztebW1Xpl0qW36+FMCrAID9+/fDwkJt2IQqIM3P/ztTIDY2FmqjvmVF9XtRvxNfVOyvmod9Vlpubq7OsZUqgCMiInSOXbx4sU5x4eHhuHDhAo4cOVKZlKpUZGSk1jlmZWXBzc0NgYGBUCqVWrEqlQrx8fEICAiAzKhvUlo521Oz9IoP8VA+PagSbVdZu+oiyH87jsImnQGpedW2/QR92qWyFRYCCxYU4urVqwgK6glrayP+jBUWQh0dDQAIevVVk50O+UX/TnzRsL9qHvZZ+Ur+Yq+LShXAZ86cwZkzZ6BSqdC0aVMAwG+//QapVIr27duLcRKJRKf2Jk6ciJ07d+LQoUOoX7++uN3Z2RmFhYV48OCB1lXgzMxMODs7izG//PKLVnsld4l4PObJO0dkZmZCqVSWuvoLAAqFAgqFotR2mUxW7puton01mlS/t4her4EebVd5u1JzMc4ocqYyyWTA9Okq7N59DdbWTYz7NZXJgPffBwBwCowX+DvxBcX+qnnYZ6Xp83pU6jZo/fr1g5+fH/744w+cPn0ap0+fxs2bN9GjRw+8+uqrOHDgAA4cOID9+/dX2I4gCJg4cSK2bduG/fv3w8PDQ2u/j48PZDIZEhISxG1XrlxBWloafH19AQC+vr44f/48bt++LcbEx8dDqVTC29tbjHm8jZKYkjaIiIiIyHRUqgBetGgRoqOjUatWLXFbrVq1sGDBAr3uAhEeHo7vvvsOGzduhK2tLTIyMpCRkYG8vDwAgJ2dHcLCwhAREYEDBw7g1KlTGD16NHx9fdG5c2cAQGBgILy9vTFixAicPXsWsbGxmDlzJsLDw8WruOPHj8f169cxffp0/Prrr1i5ciV++OEHTJkypTKnT0TPiVoNnDwpwdWr9lAb7/DfYmo1cOJE8cPokyUiMm2VGgKRlZWFO3fulNp+584dPHr0SOd2Vq1aBQDo3r271va1a9di1KhRAIAlS5bAzMwMgwYNQkFBAYKCgrBy5UoxViqVYufOnZgwYQJ8fX1hbW2N0NBQzJs3T4zx8PDArl27MGXKFCxbtgz169fHmjVreAs0IiOXnw+8/LI5gG4YM6YGTIX80kvFy5wKmYjIqFWqAB4wYABGjx6NRYsW4aW/v/B//vlnTJs2DQMHDtS5HUEQnhpjYWGBFStWYMWKFeXGuLu7Y/fu3RW20717d5w5c0bn3IiIiIjoxVSpAnj16tWYOnUqhg0bJt5zzdzcHGFhYfjkk0+qNEEiIiIioqpUqQLYysoKK1euxCeffIKUlBQAgKenpzh9MRERERGRsarUj+BKpKenIz09HY0bN4a1tbVOQxqIiIiIiAypUgXw3bt30atXLzRp0gR9+/ZFeno6ACAsLAzvvfdelSZIRERERFSVKlUAT5kyBTKZDGlpaVpTAw8ePBh79+6tsuSIiIiIiKpapcYAx8XFITY2VmvWNgBo3Lgxfv/99ypJjIhIJgNmzlTj6tWrkMk8DZ1OxWQyYM6cf5aJiMhoVaoAzsnJ0bryW+LevXtlTiFMRFQZcjkwe7YGu3dfgVxu5AWwXA5ERRk6CyIi0kGlhkB07doV33zzjbgukUig0WgQExODHj16VFlyRERERERVrVJXgGNiYtCrVy+cPHkShYWFmD59Oi5evIh79+7h6NGjVZ0jEZkojQa4eBFIS7OFRmPobJ5CowEuXy5ebt4cMHumm+wQEVE1qtQ3dMuWLfHbb7+hS5cu6N+/P3JycjBw4ECcOXMGnp5G/mdKIqox8vKAdu1keOednsjLM3Q2T5GXB7RsWfww+mSJiEyb3leAVSoVevfujdWrV+Pf//53deRERERERFRt9L4CLJPJcO7cuerIhYiIiIio2lVqCMSbb76Jr776qqpzISIiIiKqdpX6EVxRURG+/vpr7Nu3Dz4+PrC2ttbav3jx4ipJjoiIiIioqulVAF+/fh0NGzbEhQsX0L59ewDAb7/9phUjkUiqLjsiIiIioiqmVwHcuHFjpKen48CBAwCKpz7+7LPP4OTkVC3JERERERFVNb0KYEEQtNb37NmDnJycKk2IiKiETAZERKhx/fp1yGQNDZ1OxWQyYOrUf5aJiMhoVWoMcIknC2IioqoklwMff6zB7t2XIJc3NHQ6FZPLgU8+MXQWRESkA73uAiGRSEqN8eWYXyIiIiKqSfQeAjFq1CgoFAoAQH5+PsaPH1/qLhBbt26tugxJJ1tSHuoc+7qnXTVmQlR1NBrgxg0gM9OyZkyFnJZWvNygAadCJiIyYnoVwKGhoVrrb775ZpUmQ2TK+D8xpeXlAU2ayAAE4o03VPj7/72NU14e4OFRvJydDTxxYYCIiIyHXgXw2rVrqysPIiIiIqLngn+jIyIiIiKTwgKYiIiIiEwKC2AiIiIiMikGLYAPHTqEfv36wdXVFRKJBNu3b9faP2rUKPHWayWP3r17a8Xcu3cPw4cPh1KphL29PcLCwpCdna0Vc+7cOXTt2hUWFhZwc3NDTExMdZ8aERERERkpgxbAOTk5aNOmDVasWFFuTO/evZGeni4+vv/+e639w4cPx8WLFxEfH4+dO3fi0KFDGDdunLg/KysLgYGBcHd3x6lTp/DJJ58gKioKX375ZbWdFxEREREZr2eaCe5Z9enTB3369KkwRqFQwNnZucx9ly9fxt69e3HixAl06NABAPD555+jb9+++PTTT+Hq6ooNGzagsLAQX3/9NeRyOVq0aIHk5GQsXrxYq1AmIuNjbg6MH6/G77+nwdy8vqHTqZi5OfB///fPMhERGS2j/5ZOTEyEo6MjatWqhZ49e2LBggWoXbs2ACApKQn29vZi8QsA/v7+MDMzw88//4wBAwYgKSkJfn5+kMvlYkxQUBAWLlyI+/fvo1atWqWOWVBQgIKCAnE9KysLAKBSqaBSqbRiS9af3P7cqYt0DtUrVz3arc62q6zdkn2PxRhFztXddg1lZgYsWqRCfPw5mJk5wahP28wMWLr0n3WjTrb6GM13IumE/VXzsM/Kp89rYtQFcO/evTFw4EB4eHggJSUFH3zwAfr06YOkpCRIpVJkZGTA0dFR6znm5uZwcHBARkYGACAjIwMeJTen/5uTk5O4r6wCODo6GnPnzi21PS4uDlZWVmXmGh8fX6lzrCryp4eIdl+unnars+2qblf+2/Fqa7sy7VZ32y8CQ3/GSD/sr5qF/VXzsM9Ky83N1TnWqAvgIUOGiMutWrVC69at4enpicTERPTq1avajhsZGYmIiAhxPSsrC25ubggMDIRSqdSKValUiI+PR0BAAGQyWbXl9DTbU7N0jg3xUD49qBLtVmfbVdauugjy346jsElnQGpetW0/QZ92q7vtmkoQgPR0FQ4ePIhBg7pBLjfcZ+ypBAH466/i5Tp1AInEsPkYiLF8J5Ju2F81D/usfCV/sdeFURfAT2rUqBHq1KmDa9euoVevXnB2dsbt27e1YoqKinDv3j1x3LCzszMyMzO1YkrWyxtbrFAooChjzlWZTFbum62ifc+FVPeu1CtPPdqtzrarvF2puRhnFDlXd9s1VE4O0LChDEAf/OtfKlhbG/F55+QA9eoVL3MqZMN/J5Je2F81D/usNH1ejxp1H+A//vgDd+/ehYuLCwDA19cXDx48wKlTp8SY/fv3Q6PRoFOnTmLMoUOHtMaFxMfHo2nTpmUOfyAiIiKiF5tBC+Ds7GwkJycjOTkZAJCamork5GSkpaUhOzsb06ZNw/Hjx3Hjxg0kJCSgf//+8PLyQlBQEACgefPm6N27N8aOHYtffvkFR48excSJEzFkyBC4uroCAIYNGwa5XI6wsDBcvHgRmzdvxrJly7SGOBARERGR6TBoAXzy5Em0a9cO7dq1AwBERESgXbt2mD17NqRSKc6dO4d//etfaNKkCcLCwuDj44PDhw9rDU/YsGEDmjVrhl69eqFv377o0qWL1j1+7ezsEBcXh9TUVPj4+OC9997D7NmzeQs0IiIiIhNl0DHA3bt3hyAI5e6PjY19ahsODg7YuHFjhTGtW7fG4cOH9c6PiIiIiF48NWoMMBERERHRs2IBTEREREQmpUbdBo2ITIu5OTBihAZ//PEHzM1dDJ1OxczNgdDQf5aJiMho8VuaiIyWQgF89ZUau3efgUJh5AWwQgGsW2foLIiISAccAkFEREREJoVXgInIaAlC8QRr+flSVHDDGOMgCEDJPPRWViY7FTIRUU3AApiIjFZuLlCrlgzAq7h/XwW53NAZVSA3F7CxKV7mVMhEREaNQyCIiIiIyKSwACYiIiIik8ICmIiIiIhMCgtgIiIiIjIpLICJiIiIyKSwACYiIiIik8LboBGR0ZJKgYEDNcjISIdU6mjodComlQKvvfbPMhERGS0WwERktCwsgE2b1Ni9+yQsLPoaOp2KWVgAW7YYOgsiItIBh0AQERERkUlhAUxEREREJoVDIIjIaOXkADY2MgD9cf++Cvb2hs6oAsXJFi9zKmQiIqPGK8BEREREZFJYABMRERGRSWEBTEREREQmhQUwEREREZkUFsBEREREZFJYABMRERGRSeFt0IjIaEmlQJ8+Gty+fRtSaW1Dp1MxqRTo2/efZSIiMloGvQJ86NAh9OvXD66urpBIJNi+fbvWfkEQMHv2bLi4uMDS0hL+/v64evWqVsy9e/cwfPhwKJVK2NvbIywsDNnZ2Vox586dQ9euXWFhYQE3NzfExMRU96kRURWwsAB++kmNWbN+hoWFobN5CgsLYNeu4ofRJ0tEZNoMegU4JycHbdq0wVtvvYWBAweW2h8TE4PPPvsM69evh4eHB2bNmoWgoCBcunQJFn//AzN8+HCkp6cjPj4eKpUKo0ePxrhx47Bx40YAQFZWFgIDA+Hv74/Vq1fj/PnzeOutt2Bvb49x48Y91/MlMoQtKQ91jn3d064aMyEiIjIOBi2A+/Tpgz59+pS5TxAELF26FDNnzkT//v0BAN988w2cnJywfft2DBkyBJcvX8bevXtx4sQJdOjQAQDw+eefo2/fvvj000/h6uqKDRs2oLCwEF9//TXkcjlatGiB5ORkLF68mAUwERERkQky2jHAqampyMjIgL+/v7jNzs4OnTp1QlJSEoYMGYKkpCTY29uLxS8A+Pv7w8zMDD///DMGDBiApKQk+Pn5QS6XizFBQUFYuHAh7t+/j1q1apU6dkFBAQoKCsT1rKwsAIBKpYJKpdKKLVl/cvtzpy7SOVSvXPVotzrbrrJ2S/Y9FmMUOVdn29WZczXLyQHq1TOHWh2MmzcLjX4qZPN69QAARX/+abJTIRvNdyLphP1V87DPyqfPa2K0BXBGRgYAwMnJSWu7k5OTuC8jIwOOjo5a+83NzeHg4KAV4+HhUaqNkn1lFcDR0dGYO3duqe1xcXGwsrIqM9/4+HhdTqvayJ8eItp9uXrarc62q7pd+W/Hq63tyrRbnW1XZ87VLT9fitzcVwGYY//+vbCwUBs6pXJJ8/Pxam4uACA2NhZqEx8HbOjvRNIP+6vmYZ+Vlvv3d7AujLYANqTIyEhERESI61lZWXBzc0NgYCCUSqVWrEqlQnx8PAICAiCTyZ53qqLtqVk6x4Z4KJ8eVIl2q7PtKmtXXQT5b8dR2KQzIDWv2rafoE+71dl2deZc3XJy/lnu2bMn7O0N9xl7qseSDQoKMukrwMbwnUi6YX/VPOyz8pX8xV4XRlsAOzs7AwAyMzPh4uIibs/MzETbtm3FmNu3b2s9r6ioCPfu3ROf7+zsjMzMTK2YkvWSmCcpFAooFIpS22UyWblvtor2PRdS3btSrzz1aLc6267ydqXmYpxR5FydbVdnztXs8XQM/hl7msdyk8lk2smbIKPvL9LC/qp52Gel6fN6GO1EGB4eHnB2dkZCQoK4LSsrCz///DN8fX0BAL6+vnjw4AFOnTolxuzfvx8ajQadOnUSYw4dOqQ1LiQ+Ph5NmzYtc/gDEREREb3YDFoAZ2dnIzk5GcnJyQCKf/iWnJyMtLQ0SCQSTJ48GQsWLMCOHTtw/vx5jBw5Eq6urggJCQEANG/eHL1798bYsWPxyy+/4OjRo5g4cSKGDBkCV1dXAMCwYcMgl8sRFhaGixcvYvPmzVi2bJnWEAciIiIiMh0GHQJx8uRJ9OjRQ1wvKUpDQ0Oxbt06TJ8+HTk5ORg3bhwePHiALl26YO/eveI9gAFgw4YNmDhxInr16gUzMzMMGjQIn332mbjfzs4OcXFxCA8Ph4+PD+rUqYPZs2fzFmhEREREJsqgBXD37t0hCEK5+yUSCebNm4d58+aVG+Pg4CBOelGe1q1b4/Dhw5XOk4gMw8wM8PPT4O7dezAzM/JJOszMgG7d/lkmIiKjZbQ/giMisrQE9u1TY/fuo7C07GvodCpmaQkkJho6CyIi0gEvUxARERGRSWEBTEREREQmhUMgiMho5eQADRuao7CwN37/HUY/FTIaNixevnHDZCfCICKqCVgAE5FR++svCQAFgBow7/1ffxk6AyIi0gGHQBARERGRSWEBTEREREQmhQUwEREREZkUFsBEREREZFJYABMRERGRSeFdIIjIaJmZAT4+Gjx8+BBmZjaGTqdiZmZAhw7/LBMRkdFiAUxERsvSEkhKUmP37kM1YyrkEycMnQUREemAlymIiIiIyKSwACYiIiIik8IhEERktHJzAW9vc+TmBuDqVcDOztAZVaA42eLlS5cAKyvD5kNEROViAUxERksQgN9/lwCwgiAY+VTIxcn+s0xEREaLQyCIiIiIyKSwACYiIiIik8IhEERUaVtSHuoc+7qnMQ/gJSIiU8IrwERERERkUlgAExEREZFJ4RAIIjJaEgnQvLmA7OxHkEgsDZ1OxSSSf26DJpEYNhciIqoQC2AiMlpWVsDZs0XYvfsArKyMfCpkKyvg4kVDZ0FERDrgEAgiIiIiMiksgImIiIjIpHAIBBEZrdxcoEMHc2Rn90D37jVgKuSOHYuXT5zgVMhEREbMqK8AR0VFQSKRaD2aNWsm7s/Pz0d4eDhq164NGxsbDBo0CJmZmVptpKWlITg4GFZWVnB0dMS0adNQVFT0vE+FiCpBEIDLlyW4eVNp/LMLCwJw6VLxw+iTJSIybUZ/BbhFixbYt2+fuG5u/k/KU6ZMwa5du7BlyxbY2dlh4sSJGDhwII4ePQoAUKvVCA4OhrOzM44dO4b09HSMHDkSMpkMH3300XM/FyIiIiIyPKMvgM3NzeHs7Fxq+8OHD/HVV19h48aN6NmzJwBg7dq1aN68OY4fP47OnTsjLi4Oly5dwr59++Dk5IS2bdti/vz5mDFjBqKioiCXy8s8ZkFBAQoKCsT1rKwsAIBKpYJKpdKKLVl/cvtzp9b9qrZeuerRbnW2XWXtlux7LMYocq7OtmtizuJzAEAmPt/QH7MKqVR/Z/r3uRp1stXHaL4TSSfsr5qHfVY+fV4Toy+Ar169CldXV1hYWMDX1xfR0dFo0KABTp06BZVKBX9/fzG2WbNmaNCgAZKSktC5c2ckJSWhVatWcHJyEmOCgoIwYcIEXLx4Ee3atSvzmNHR0Zg7d26p7XFxcbAqZ1xffHz8M57psym7lC/b7svV0251tl3V7cp/O15tbVem3epsuybmXCI/XwrgVQDA/v37YWGh1r+R50San/93pkBsbCzUFhYGzcfQDP2dSPphf9U87LPScnNzdY416gK4U6dOWLduHZo2bYr09HTMnTsXXbt2xYULF5CRkQG5XA57e3ut5zg5OSEjIwMAkJGRoVX8luwv2VeeyMhIREREiOtZWVlwc3NDYGAglEqlVqxKpUJ8fDwCAgIgk8mebOq52Z6apXNsiIfy6UGVaLc6266ydtVFkP92HIVNOgNS86pt+wn6tFudbdfEnEvk5Pyz3LNnT9jbG+4z9lSPJRsUFARYWxswGcMxlu9E0g37q+Zhn5Wv5C/2ujDqArhPnz7icuvWrdGpUye4u7vjhx9+gKVl9c0KpVAooFAoSm2XyWTlvtkq2vdcSHXvSr3y1KPd6my7ytuVmotxRpFzdbZdE3MWn6P9fKP+sn8sN5lMpp28CTL6/iIt7K+ah31Wmj6vh1HfBeJJ9vb2aNKkCa5duwZnZ2cUFhbiwYMHWjGZmZnimGFnZ+dSd4UoWS9rXDERGReJBHB3F1C3bq7xzy5cnGzxw+iTJSIybTWqAM7OzkZKSgpcXFzg4+MDmUyGhIQEcf+VK1eQlpYGX19fAICvry/Onz+P27dvizHx8fFQKpXw9vZ+7vkTkX6srICrV4vwn//EG/9tda2sgBs3ih9GnywRkWkz6iEQU6dORb9+/eDu7o5bt25hzpw5kEqlGDp0KOzs7BAWFoaIiAg4ODhAqVRi0qRJ8PX1RefOnQEAgYGB8Pb2xogRIxATE4OMjAzMnDkT4eHhZQ5xICIiIqIXn1EXwH/88QeGDh2Ku3fvom7duujSpQuOHz+OunXrAgCWLFkCMzMzDBo0CAUFBQgKCsLKlSvF50ulUuzcuRMTJkyAr68vrK2tERoainnz5hnqlIiIiIjIwIy6AN60aVOF+y0sLLBixQqsWLGi3Bh3d3fs3r27qlMjoucgLw/o2lWKhw/90KOHkf+uLC8P8PMrXj50CKjGH+oSEdGzMeoCmIhMm0YDnDplBqAWNBojv+m7RgOcPPnPMhERGa0a9SM4IiIiIqJnxQKYiIiIiEwKh0AQkdHZkvIQAJCfCwB2AID/3ciChW3pr6zXPe2eY2ZERPQi4BVgIiIiIjIpLICJiIiIyKRwCAQRGTXbWhpI1EZ+B4gSdeoYOgMiItIBC2AiMloWVsBXx+9DfvkICq26GDqdillbA3fuGDoLIiLSAYdAEBEREZFJ4RVgI1byS3giIiIiqjq8AkxERqswH4gaocS///0KCvMNnc1T5OUB3bsXP/LyDJ0NERFVgFeAichoaTTApV9kAOpAo7lr6HQqptEABw/+s0xEREaLV4CJiIiIyKSwACYiIiIik8IhEERkUvT5cSmnWSYiejHxCjARERERmRQWwERERERkUjgEgoiMmsJSADRqQ6ehGysrQ2dAREQ6YAFMREbLwgr4NvlezZkKOSfH0FkQEZEOOASCiIiIiEwKrwATEVUBfacu5x0miIgMh1eAichoFRYA0eNsMX9+JxQWGDqbipkV5KPLmDfQZcwbMCsw9nmbiYhMG68AE5HR0qiBMwflAJyhURv3VMgStRouiXHiMhERGS8WwERERo6TdxARVS0OgSAiIiIik2JSBfCKFSvQsGFDWFhYoFOnTvjll18MnRIRERERPWcmMwRi8+bNiIiIwOrVq9GpUycsXboUQUFBuHLlChwdHQ2dHhHRc8c7VxCRqTKZAnjx4sUYO3YsRo8eDQBYvXo1du3aha+//hrvv/++gbMjIjJdHONMRM+bSRTAhYWFOHXqFCIjI8VtZmZm8Pf3R1JSUqn4goICFBT8c8+lhw+Lv5zv3bsHlUqlFatSqZCbm4u7d+9CJpNVad65Dx9VaXsl7t4tqrYcqqvtKmtXXYSi3FwUPrwPSM2rtu0n6NNudbZdk3MuyAUACQAg7+F9aDSlv7KMJ+f7yHpsWa0qrMK2Df/eAID1p+8/PUhdBLme34nV+R7d+bvubb/qblst7VZn2/q0W5bq/DeMqgf7rHyPHhV/dgRBeGqsSRTAf/31F9RqNZycnLS2Ozk54ddffy0VHx0djblz55ba7uHhUW05ElHF3u5u6Az00LWloTMgIjJZjx49gp1dxX8tMokCWF+RkZGIiIgQ1zUaDe7du4fatWtDIpFoxWZlZcHNzQ03b96EUql83qmSnthfNQ/7rGZhf9Us7K+ah31WPkEQ8OjRI7i6uj411iQK4Dp16kAqlSIzM1Nre2ZmJpydnUvFKxQKKBQKrW329vYVHkOpVPKNWIOwv2oe9lnNwv6qWdhfNQ/7rGxPu/JbwiRugyaXy+Hj44OEhARxm0ajQUJCAnx9fQ2YGRERERE9byZxBRgAIiIiEBoaig4dOuCll17C0qVLkZOTI94VgoiIiIhMg8kUwIMHD8adO3cwe/ZsZGRkoG3btti7d2+pH8bpS6FQYM6cOaWGTJBxYn/VPOyzmoX9VbOwv2oe9lnVkAi63CuCiIiIiOgFYRJjgImIiIiISrAAJiIiIiKTwgKYiIiIiEwKC2AiIiIiMiksgJ/BihUr0LBhQ1hYWKBTp0745ZdfDJ0SlSMqKgoSiUTr0axZM0OnRX87dOgQ+vXrB1dXV0gkEmzfvl1rvyAImD17NlxcXGBpaQl/f39cvXrVMMkSgKf32ahRo0p95nr37m2YZAnR0dHo2LEjbG1t4ejoiJCQEFy5ckUrJj8/H+Hh4ahduzZsbGwwaNCgUhNI0fOhS39179691Gds/PjxBsq45mEBXEmbN29GREQE5syZg9OnT6NNmzYICgrC7du3DZ0alaNFixZIT08XH0eOHDF0SvS3nJwctGnTBitWrChzf0xMDD777DOsXr0aP//8M6ytrREUFIT8/PznnCmVeFqfAUDv3r21PnPff//9c8yQHnfw4EGEh4fj+PHjiI+Ph0qlQmBgIHJycsSYKVOm4H//+x+2bNmCgwcP4tatWxg4cKABszZduvQXAIwdO1brMxYTE2OgjGsggSrlpZdeEsLDw8V1tVotuLq6CtHR0QbMisozZ84coU2bNoZOg3QAQNi2bZu4rtFoBGdnZ+GTTz4Rtz148EBQKBTC999/b4AM6UlP9pkgCEJoaKjQv39/g+RDT3f79m0BgHDw4EFBEIo/UzKZTNiyZYsYc/nyZQGAkJSUZKg06W9P9pcgCEK3bt2Ed99913BJ1XC8AlwJhYWFOHXqFPz9/cVtZmZm8Pf3R1JSkgEzo4pcvXoVrq6uaNSoEYYPH460tDRDp0Q6SE1NRUZGhtbnzc7ODp06deLnzcglJibC0dERTZs2xYQJE3D37l1Dp0R/e/jwIQDAwcEBAHDq1CmoVCqtz1mzZs3QoEEDfs6MwJP9VWLDhg2oU6cOWrZsicjISOTm5hoivRrJZGaCq0p//fUX1Gp1qVnknJyc8OuvvxooK6pIp06dsG7dOjRt2hTp6emYO3cuunbtigsXLsDW1tbQ6VEFMjIyAKDMz1vJPjI+vXv3xsCBA+Hh4YGUlBR88MEH6NOnD5KSkiCVSg2dnknTaDSYPHkyXnnlFbRs2RJA8edMLpfD3t5eK5afM8Mrq78AYNiwYXB3d4erqyvOnTuHGTNm4MqVK9i6dasBs605WACTSejTp4+43Lp1a3Tq1Anu7u744YcfEBYWZsDMiF5MQ4YMEZdbtWqF1q1bw9PTE4mJiejVq5cBM6Pw8HBcuHCBv4OoIcrrr3HjxonLrVq1gouLC3r16oWUlBR4eno+7zRrHA6BqIQ6depAKpWW+nVsZmYmnJ2dDZQV6cPe3h5NmjTBtWvXDJ0KPUXJZ4qft5qtUaNGqFOnDj9zBjZx4kTs3LkTBw4cQP369cXtzs7OKCwsxIMHD7Ti+TkzrPL6qyydOnUCAH7GdMQCuBLkcjl8fHyQkJAgbtNoNEhISICvr68BMyNdZWdnIyUlBS4uLoZOhZ7Cw8MDzs7OWp+3rKws/Pzzz/y81SB//PEH7t69y8+cgQiCgIkTJ2Lbtm3Yv38/PDw8tPb7+PhAJpNpfc6uXLmCtLQ0fs4M4Gn9VZbk5GQA4GdMRxwCUUkREREIDQ1Fhw4d8NJLL2Hp0qXIycnB6NGjDZ0alWHq1Kno168f3N3dcevWLcyZMwdSqRRDhw41dGqE4v8hefyqRWpqKpKTk+Hg4IAGDRpg8uTJWLBgARo3bgwPDw/MmjULrq6uCAkJMVzSJq6iPnNwcMDcuXMxaNAgODs7IyUlBdOnT4eXlxeCgoIMmLXpCg8Px8aNG/HTTz/B1tZWHNdrZ2cHS0tL2NnZISwsDBEREXBwcIBSqcSkSZPg6+uLzp07Gzh70/O0/kpJScHGjRvRt29f1K5dG+fOncOUKVPg5+eH1q1bGzj7GsLQt6GoyT7//HOhQYMGglwuF1566SXh+PHjhk6JyjF48GDBxcVFkMvlQr169YTBgwcL165dM3Ra9LcDBw4IAEo9QkNDBUEovhXarFmzBCcnJ0GhUAi9evUSrly5YtikTVxFfZabmysEBgYKdevWFWQymeDu7i6MHTtWyMjIMHTaJqusvgIgrF27VozJy8sT/u///k+oVauWYGVlJQwYMEBIT083XNIm7Gn9lZaWJvj5+QkODg6CQqEQvLy8hGnTpgkPHz40bOI1iEQQBOF5FtxERERERIbEMcBEREREZFJYABMRERGRSWEBTEREREQmhQUwEREREZkUFsBEREREZFJYABMRERGRSWEBTEREREQmhQUwEREREZkUFsBERPTCkEgk2L59u6HTICIjxwKYiOgxd+7cwYQJE9CgQQMoFAo4OzsjKCgIR48eNXRqRsMYisyoqCi0bdvWoDkQUc1lbugEiIiMyaBBg1BYWIj169ejUaNGyMzMREJCAu7evWvo1IiIqIrwCjAR0d8ePHiAw4cPY+HChejRowfc3d3x0ksvITIyEv/617+04saMGYO6detCqVSiZ8+eOHv2rFZbH3/8MZycnGBra4uwsDC8//77Wlcsu3fvjsmTJ2s9JyQkBKNGjRLXCwoKMHXqVNSrVw/W1tbo1KkTEhMTxf3r1q2Dvb09YmNj0bx5c9jY2KB3795IT0/Xavfrr79GixYtoFAo4OLigokTJ+p1Lvpas2YNmjdvDgsLCzRr1gwrV64U9924cQMSiQRbt25Fjx49YGVlhTZt2iApKUmrjf/85z9wc3ODlZUVBgwYgMWLF8Pe3l4877lz5+Ls2bOQSCSQSCRYt26d+Ny//voLAwYMgJWVFRo3bowdO3Y80/kQ0YuHBTAR0d9sbGxgY2OD7du3o6CgoNy4119/Hbdv38aePXtw6tQptG/fHr169cK9e/cAAD/88AOioqLw0Ucf4eTJk3BxcdEqAnU1ceJEJCUlYdOmTTh37hxef/119O7dG1evXhVjcnNz8emnn+Lbb7/FoUOHkJaWhqlTp4r7V61ahfDwcIwbNw7nz5/Hjh074OXlpfO56GvDhg2YPXs2PvzwQ1y+fBkfffQRZs2ahfXr12vF/fvf/8bUqVORnJyMJk2aYOjQoSgqKgIAHD16FOPHj8e7776L5ORkBAQE4MMPPxSfO3jwYLz33nto0aIF0tPTkZ6ejsGDB4v7586dizfeeAPnzp1D3759MXz48EqfDxG9oAQiIhL9+OOPQq1atQQLCwvh5ZdfFiIjI4WzZ8+K+w8fPiwolUohPz9f63menp7CF198IQiCIPj6+gr/93//p7W/U6dOQps2bcT1bt26Ce+++65WTP/+/YXQ0FBBEATh999/F6RSqfDnn39qxfTq1UuIjIwUBEEQ1q5dKwAQrl27Ju5fsWKF4OTkJK67uroK//73v8s8V13OpSwAhG3btpW5z9PTU9i4caPWtvnz5wu+vr6CIAhCamqqAEBYs2aNuP/ixYsCAOHy5cuCIAjC4MGDheDgYK02hg8fLtjZ2Ynrc+bM0Xo9H89t5syZ4np2drYAQNizZ0+550NEpodXgImIHjNo0CDcunULO3bsQO/evZGYmIj27duLf2I/e/YssrOzUbt2bfGKsY2NDVJTU5GSkgIAuHz5Mjp16qTVrq+vr155nD9/Hmq1Gk2aNNE6zsGDB8XjAICVlRU8PT3FdRcXF9y+fRsAcPv2bdy6dQu9evUq8xi6nIs+cnJykJKSgrCwMK32FixYUKq91q1ba+Vcki8AXLlyBS+99JJW/JPrFXm8bWtrayiVSrFtIiKAP4IjIirFwsICAQEBCAgIwKxZszBmzBjMmTMHo0aNQnZ2NlxcXLTG4pYoGaOqCzMzMwiCoLVNpVKJy9nZ2ZBKpTh16hSkUqlWnI2Njbgsk8m09kkkErFdS0vLCnOoqnN5vD2gePzuk/8D8OQ5PJ63RCIBAGg0Gr2PWZayXpOqapuIXgwsgImInsLb21u87Vf79u2RkZEBc3NzNGzYsMz45s2b4+eff8bIkSPFbcePH9eKqVu3rtaP1dRqNS5cuIAePXoAANq1awe1Wo3bt2+ja9eulcrb1tYWDRs2REJCgtju43Q5F304OTnB1dUV169fx/DhwyvdTtOmTXHixAmtbU+uy+VyqNXqSh+DiEwbC2Aior/dvXsXr7/+Ot566y20bt0atra2OHnyJGJiYtC/f38AgL+/P3x9fRESEoKYmBg0adIEt27dwq5duzBgwAB06NAB7777LkaNGoUOHTrglVdewYYNG3Dx4kU0atRIPFbPnj0RERGBXbt2wdPTE4sXL8aDBw/E/U2aNMHw4cMxcuRILFq0CO3atcOdO3eQkJCA1q1bIzg4WKdzioqKwvjx4+Ho6Ig+ffrg0aNHOHr0KCZNmqTTuZQnNTUVycnJWtsaN26MuXPn4p133oGdnR169+6NgoICnDx5Evfv30dERIROOU+aNAl+fn5YvHgx+vXrh/3792PPnj3ilWIAaNiwoZhD/fr1YWtrC4VCoVP7RET8ERwR0d/y8/OF999/X2jfvr1gZ2cnWFlZCU2bNhVmzpwp5ObminFZWVnCpEmTBFdXV0Emkwlubm7C8OHDhbS0NDHmww8/FOrUqSPY2NgIoaGhwvTp07V+tFVYWChMmDBBcHBwEBwdHYXo6GitH8GVxMyePVto2LChIJPJBBcXF2HAgAHCuXPnBEEo/hHc4z8MEwRB2LZtm/DkV/vq1auFpk2bim1MmjRJr3N5EoAyH4cPHxYEQRA2bNggtG3bVpDL5UKtWrUEPz8/YevWrYIg/PMjuDNnzojt3b9/XwAgHDhwQNz25ZdfCvXq1RMsLS2FkJAQYcGCBYKzs7NWXw0aNEiwt7cXAAhr164Vc3vyB3p2dnbifiIiQRAEiSA8MQiNiIiqXFRUFLZv317qqinpZuzYsfj1119x+PBhQ6dCRC8ADoEgIiKj8+mnnyIgIADW1tbYs2cP1q9fX6l7KRMRlYUFMBERGZ1ffvkFMTExePToERo1aoTPPvsMY8aMMXRaRPSC4BAIIiIiIjIpnAiDiIiIiEwKC2AiIiIiMiksgImIiIjIpLAAJiIiIiKTwgKYiIiIiEwKC2AiIiIiMiksgImIiIjIpLAAJiIiIiKT8v/LBJ9kz2xO0wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최대 길이: 27\n",
      "평균 길이: 5.01\n",
      "97% 백분위수: 10.0\n",
      "99% 백분위수: 12.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 질문과 답변의 토큰 길이 구하기\n",
    "raw_lengths = [len(tokenizer.encode(q)) for q in raw['cleaned']]\n",
    "\n",
    "# 길이 분포 시각화\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.hist(raw_lengths, bins=50, alpha=0.7, color='skyblue', label='Lengths')\n",
    "plt.axvline(x=np.percentile(raw_lengths, 97), color='b', linestyle='--', label='97 Percentile')\n",
    "plt.axvline(x=np.percentile(raw_lengths, 99), color='r', linestyle='--', label='99 Percentile')\n",
    "\n",
    "plt.xlabel('Sequence Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Sequence Length Distribution')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 통계 분석\n",
    "print(f\"최대 길이: {np.max(raw_lengths)}\")\n",
    "print(f\"평균 길이: {np.mean(raw_lengths):.2f}\")\n",
    "print(f\"97% 백분위수: {np.percentile(raw_lengths, 97)}\")\n",
    "print(f\"99% 백분위수: {np.percentile(raw_lengths, 99)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.eos_token = '[END_TOKEN]'\n",
    "tokenizer.eos_token_id = END_TOKEN[0]\n",
    "\n",
    "tokenizer.sos_token = '[START_TOKEN]'\n",
    "tokenizer.sos_token_id = START_TOKEN[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 입력 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unsupervised Learning 이므로 pre-training시 target 데이터는 입력 데이터를 right-shift 시킨 형태로 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 샘플 99%를 활용하기 위해 최대 길이를 사용\n",
    "MAX_LENGTH = 12\n",
    "\n",
    "def create_auto_regressive_data(dataset, tokenizer=tokenizer, max_len=12):\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    \n",
    "    for sentence in dataset:\n",
    "        # 문장을 토큰화하고 패딩을 추가\n",
    "        tokens = tokenizer.encode(sentence)  # 문장을 토큰화\n",
    "        tokens = tokens[:max_len-1]  # 문장의 길이를 max_len-1로 자르기 (최대 길이 초과 방지)\n",
    "        \n",
    "        # 입력과 타겟 시퀀스 생성\n",
    "        input_seq = [tokenizer.sos_token_id] + tokens\n",
    "        target_seq = [tokenizer.sos_token_id] + tokens[1:] + [tokenizer.eos_token_id]  # target은 한 칸 오른쪽으로 shift\n",
    "        \n",
    "        # 패딩\n",
    "        input_seq = input_seq + [0] * (max_len - len(input_seq)) #padding은 0\n",
    "        target_seq = target_seq + [0] * (max_len - len(target_seq))\n",
    "        \n",
    "        inputs.append(input_seq)\n",
    "        targets.append(target_seq)\n",
    "    \n",
    "    return inputs, targets\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 : 9059\n",
      "필터링 후의 질문 샘플 개수: 19436\n",
      "필터링 후의 답변 샘플 개수: 19436\n",
      "입력 데이터 : [[9057, 5982, 1576, 4174, 0, 0, 0, 0, 0, 0, 0, 0], [9057, 8850, 33, 1047, 8833, 841, 1462, 0, 0, 0, 0, 0], [9057, 8852, 1313, 3516, 8833, 2796, 51, 0, 0, 0, 0, 0]]\n",
      "출출력 데이터 : [[9057, 1576, 4174, 9058, 0, 0, 0, 0, 0, 0, 0, 0], [9057, 33, 1047, 8833, 841, 1462, 9058, 0, 0, 0, 0, 0], [9057, 1313, 3516, 8833, 2796, 51, 9058, 0, 0, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = create_auto_regressive_data(raw['cleaned'])\n",
    "print('단어장의 크기 :',(VOCAB_SIZE))\n",
    "print('필터링 후의 질문 샘플 개수: {}'.format(len(inputs)))\n",
    "print('필터링 후의 답변 샘플 개수: {}'.format(len(targets)))\n",
    "print('입력 데이터 : {}'.format(inputs[:3]))\n",
    "print('출출력 데이터 : {}'.format(targets[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n",
      "Sample input batch: [[9057 5982 1576 4174    0    0    0    0    0    0    0    0]\n",
      " [9057 8850   33 1047 8833  841 1462    0    0    0    0    0]\n",
      " [9057 8852 1313 3516 8833 2796   51    0    0    0    0    0]\n",
      " [9057 8852 1313 3516 8833 1167 2796   51    0    0    0    0]\n",
      " [9057  448  448 9037 8952 8953 8833 3927    0    0    0    0]]\n",
      "Sample output batch: [[9057 1576 4174 9058    0    0    0    0    0    0    0    0]\n",
      " [9057   33 1047 8833  841 1462 9058    0    0    0    0    0]\n",
      " [9057 1313 3516 8833 2796   51 9058    0    0    0    0    0]\n",
      " [9057 1313 3516 8833 1167 2796   51 9058    0    0    0    0]\n",
      " [9057  448 9037 8952 8953 8833 3927 9058    0    0    0    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-17 16:38:33.561900: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:08:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-17 16:38:33.581458: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:08:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-17 16:38:33.581541: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:08:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-17 16:38:33.586797: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:08:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-17 16:38:33.586856: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:08:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-17 16:38:33.586887: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:08:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-17 16:38:33.715524: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:08:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-17 16:38:33.715620: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:08:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-17 16:38:33.715629: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2025-02-17 16:38:33.715672: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:08:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-02-17 16:38:33.715699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9711 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:08:00.0, compute capability: 8.6\n",
      "2025-02-17 16:38:34.017146: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "# numpy 배열로 변환 (필수)\n",
    "inputs = np.array(inputs, dtype=np.int32)\n",
    "outputs = np.array(targets, dtype=np.int32)\n",
    "\n",
    "# TensorFlow Dataset 생성\n",
    "dataset = tf.data.Dataset.from_tensor_slices((inputs, outputs))\n",
    "\n",
    "# 최적화 및 배치 적용\n",
    "dataset = dataset.cache()  # 데이터셋을 캐시하여 성능 최적화\n",
    "dataset = dataset.batch(BATCH_SIZE)  # 배치 크기 설정\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)  # 병렬 처리 최적화\n",
    "\n",
    "print(\"슝=3\")\n",
    "\n",
    "# 데이터 확인 (첫 번째 배치 출력)\n",
    "for batch in dataset.take(1):\n",
    "    input_batch, output_batch = batch\n",
    "    print(\"Sample input batch:\", input_batch.numpy()[:5])\n",
    "    print(\"Sample output batch:\", output_batch.numpy()[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 인스턴스화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"GPT\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " inputs (InputLayer)         [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " gpt_embedding (GPTEmbeddin  (None, None, 256)            2322176   ['inputs[0][0]']              \n",
      " g)                                                                                               \n",
      "                                                                                                  \n",
      " look_ahead_mask (Lambda)    (None, 1, None, None)        0         ['inputs[0][0]']              \n",
      "                                                                                                  \n",
      " decoder_layer_11 (Function  (None, None, 256)            527104    ['gpt_embedding[0][0]',       \n",
      " al)                                                                 'look_ahead_mask[0][0]']     \n",
      "                                                                                                  \n",
      " outputs (Dense)             (None, None, 9059)           2328163   ['decoder_layer_11[0][0]']    \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5177443 (19.75 MB)\n",
      "Trainable params: 5177443 (19.75 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 12 # 디코더의 층의 개수\n",
    "D_MODEL = 256 # 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "\n",
    "model = GPT(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    MAX_Length=MAX_LENGTH)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "    \n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')(y_true, y_pred)\n",
    "    \n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "    loss = tf.multiply(loss, mask)\n",
    "    \n",
    "    return tf.reduce_mean(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    step = tf.cast(step, tf.float32)\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH))\n",
    "  print(y_pred[:5])\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Tensor(\"strided_slice_1:0\", shape=(None, 12, 9059), dtype=float32)\n",
      "Tensor(\"strided_slice_1:0\", shape=(None, 12, 9059), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-17 16:38:37.665571: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2025-02-17 16:38:37.702923: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f7bc01c3200 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-02-17 16:38:37.702966: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3060, Compute Capability 8.6\n",
      "2025-02-17 16:38:37.707286: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-02-17 16:38:37.717420: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2025-02-17 16:38:37.773514: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2025-02-17 16:38:37.810908: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304/304 [==============================] - 24s 73ms/step - loss: 3.9412 - accuracy: 0.1265\n",
      "Epoch 2/100\n",
      "304/304 [==============================] - 6s 20ms/step - loss: 2.8790 - accuracy: 0.1671\n",
      "Epoch 3/100\n",
      "304/304 [==============================] - 6s 19ms/step - loss: 2.5808 - accuracy: 0.1736\n",
      "Epoch 4/100\n",
      "304/304 [==============================] - 6s 18ms/step - loss: 2.3538 - accuracy: 0.1841\n",
      "Epoch 5/100\n",
      "304/304 [==============================] - 6s 19ms/step - loss: 2.1151 - accuracy: 0.1974\n",
      "Epoch 6/100\n",
      "304/304 [==============================] - 6s 18ms/step - loss: 1.8646 - accuracy: 0.2121\n",
      "Epoch 7/100\n",
      "304/304 [==============================] - 5s 18ms/step - loss: 1.6118 - accuracy: 0.2271\n",
      "Epoch 8/100\n",
      "304/304 [==============================] - 6s 18ms/step - loss: 1.3687 - accuracy: 0.2421\n",
      "Epoch 9/100\n",
      "304/304 [==============================] - 6s 19ms/step - loss: 1.1438 - accuracy: 0.2602\n",
      "Epoch 10/100\n",
      "304/304 [==============================] - 6s 19ms/step - loss: 0.9540 - accuracy: 0.2855\n",
      "Epoch 11/100\n",
      "304/304 [==============================] - 6s 19ms/step - loss: 0.8059 - accuracy: 0.3136\n",
      "Epoch 12/100\n",
      "304/304 [==============================] - 6s 20ms/step - loss: 0.6783 - accuracy: 0.3410\n",
      "Epoch 13/100\n",
      "304/304 [==============================] - 6s 19ms/step - loss: 0.5790 - accuracy: 0.3638\n",
      "Epoch 14/100\n",
      "304/304 [==============================] - 6s 18ms/step - loss: 0.5083 - accuracy: 0.3800\n",
      "Epoch 15/100\n",
      "304/304 [==============================] - 6s 18ms/step - loss: 0.4592 - accuracy: 0.3916\n",
      "Epoch 16/100\n",
      "304/304 [==============================] - 5s 18ms/step - loss: 0.4139 - accuracy: 0.4026\n",
      "Epoch 17/100\n",
      "304/304 [==============================] - 5s 18ms/step - loss: 0.3877 - accuracy: 0.4085\n",
      "Epoch 18/100\n",
      "304/304 [==============================] - 5s 18ms/step - loss: 0.3593 - accuracy: 0.4149\n",
      "Epoch 19/100\n",
      "304/304 [==============================] - 5s 18ms/step - loss: 0.3462 - accuracy: 0.4179\n",
      "Epoch 20/100\n",
      "304/304 [==============================] - 5s 17ms/step - loss: 0.3203 - accuracy: 0.4223\n",
      "Epoch 21/100\n",
      "304/304 [==============================] - 5s 18ms/step - loss: 0.3066 - accuracy: 0.4254\n",
      "Epoch 22/100\n",
      "304/304 [==============================] - 5s 17ms/step - loss: 0.2949 - accuracy: 0.4270\n",
      "Epoch 23/100\n",
      "304/304 [==============================] - 5s 18ms/step - loss: 0.2868 - accuracy: 0.4295\n",
      "Epoch 24/100\n",
      "304/304 [==============================] - 5s 17ms/step - loss: 0.2784 - accuracy: 0.4301\n",
      "Epoch 25/100\n",
      "304/304 [==============================] - 5s 17ms/step - loss: 0.2707 - accuracy: 0.4316\n",
      "Epoch 26/100\n",
      "304/304 [==============================] - 5s 17ms/step - loss: 0.2659 - accuracy: 0.4321\n",
      "Epoch 27/100\n",
      "304/304 [==============================] - 5s 17ms/step - loss: 0.2599 - accuracy: 0.4335\n",
      "Epoch 28/100\n",
      "304/304 [==============================] - 5s 17ms/step - loss: 0.2577 - accuracy: 0.4337\n",
      "Epoch 29/100\n",
      "304/304 [==============================] - 5s 17ms/step - loss: 0.2522 - accuracy: 0.4346\n",
      "Epoch 30/100\n",
      "304/304 [==============================] - 5s 17ms/step - loss: 0.2477 - accuracy: 0.4355\n",
      "Epoch 31/100\n",
      "304/304 [==============================] - 5s 18ms/step - loss: 0.2459 - accuracy: 0.4357\n",
      "Epoch 32/100\n",
      "304/304 [==============================] - 5s 18ms/step - loss: 0.2395 - accuracy: 0.4362\n",
      "Epoch 33/100\n",
      "304/304 [==============================] - 5s 18ms/step - loss: 0.2348 - accuracy: 0.4369\n",
      "Epoch 34/100\n",
      "304/304 [==============================] - 5s 17ms/step - loss: 0.2325 - accuracy: 0.4370\n",
      "Epoch 35/100\n",
      "304/304 [==============================] - 5s 17ms/step - loss: 0.2263 - accuracy: 0.4378\n",
      "Epoch 36/100\n",
      "304/304 [==============================] - 5s 17ms/step - loss: 0.2264 - accuracy: 0.4378\n",
      "Epoch 37/100\n",
      "304/304 [==============================] - 5s 18ms/step - loss: 0.2212 - accuracy: 0.4387\n",
      "Epoch 38/100\n",
      "304/304 [==============================] - 5s 18ms/step - loss: 0.2176 - accuracy: 0.4385\n",
      "Epoch 39/100\n",
      "304/304 [==============================] - 5s 18ms/step - loss: 0.2113 - accuracy: 0.4398\n",
      "Epoch 40/100\n",
      "304/304 [==============================] - 5s 17ms/step - loss: 0.2119 - accuracy: 0.4396\n",
      "Epoch 41/100\n",
      "304/304 [==============================] - 5s 18ms/step - loss: 0.2089 - accuracy: 0.4401\n",
      "Epoch 42/100\n",
      "304/304 [==============================] - 5s 17ms/step - loss: 0.2062 - accuracy: 0.4402\n",
      "Epoch 43/100\n",
      "304/304 [==============================] - 6s 18ms/step - loss: 0.2025 - accuracy: 0.4407\n",
      "Epoch 44/100\n",
      "304/304 [==============================] - 6s 18ms/step - loss: 0.2031 - accuracy: 0.4406\n",
      "Epoch 45/100\n",
      "304/304 [==============================] - 5s 17ms/step - loss: 0.2005 - accuracy: 0.4409\n",
      "Epoch 46/100\n",
      "304/304 [==============================] - 5s 18ms/step - loss: 0.2015 - accuracy: 0.4402\n",
      "Epoch 47/100\n",
      "304/304 [==============================] - 5s 18ms/step - loss: 0.1986 - accuracy: 0.4408\n",
      "Epoch 48/100\n",
      "304/304 [==============================] - 6s 19ms/step - loss: 0.1967 - accuracy: 0.4405\n",
      "Epoch 49/100\n",
      "304/304 [==============================] - 6s 18ms/step - loss: 0.1949 - accuracy: 0.4409\n",
      "Epoch 50/100\n",
      "304/304 [==============================] - 6s 18ms/step - loss: 0.1962 - accuracy: 0.4404\n",
      "Epoch 51/100\n",
      "304/304 [==============================] - 6s 19ms/step - loss: 0.1945 - accuracy: 0.4407\n",
      "Epoch 52/100\n",
      "304/304 [==============================] - 6s 18ms/step - loss: 0.1925 - accuracy: 0.4410\n",
      "Epoch 53/100\n",
      "304/304 [==============================] - 6s 18ms/step - loss: 0.1929 - accuracy: 0.4409\n",
      "Epoch 54/100\n",
      "304/304 [==============================] - 6s 19ms/step - loss: 0.1916 - accuracy: 0.4412\n",
      "Epoch 55/100\n",
      "304/304 [==============================] - 6s 19ms/step - loss: 0.1939 - accuracy: 0.4403\n",
      "Epoch 56/100\n",
      "304/304 [==============================] - 6s 18ms/step - loss: 0.1923 - accuracy: 0.4405\n",
      "Epoch 57/100\n",
      "304/304 [==============================] - 5s 17ms/step - loss: 0.1933 - accuracy: 0.4403\n",
      "Epoch 58/100\n",
      "304/304 [==============================] - 5s 18ms/step - loss: 0.1907 - accuracy: 0.4409\n",
      "Epoch 59/100\n",
      "304/304 [==============================] - 6s 18ms/step - loss: 0.1913 - accuracy: 0.4406\n",
      "Epoch 60/100\n",
      "304/304 [==============================] - 5s 18ms/step - loss: 0.1892 - accuracy: 0.4408\n",
      "Epoch 61/100\n",
      "304/304 [==============================] - 6s 18ms/step - loss: 0.1891 - accuracy: 0.4409\n",
      "Epoch 62/100\n",
      "304/304 [==============================] - 5s 17ms/step - loss: 0.1892 - accuracy: 0.4409\n",
      "Epoch 63/100\n",
      "304/304 [==============================] - 5s 17ms/step - loss: 0.1883 - accuracy: 0.4407\n",
      "Epoch 64/100\n",
      "304/304 [==============================] - 5s 17ms/step - loss: 0.1873 - accuracy: 0.4406\n",
      "Epoch 65/100\n",
      "304/304 [==============================] - 5s 17ms/step - loss: 0.1854 - accuracy: 0.4412\n",
      "Epoch 66/100\n",
      "304/304 [==============================] - 5s 17ms/step - loss: 0.1840 - accuracy: 0.4410\n",
      "Epoch 67/100\n",
      "304/304 [==============================] - 5s 17ms/step - loss: 0.1840 - accuracy: 0.4411\n",
      "Epoch 68/100\n",
      "304/304 [==============================] - 5s 17ms/step - loss: 0.1823 - accuracy: 0.4417\n",
      "Epoch 69/100\n",
      "304/304 [==============================] - 5s 17ms/step - loss: 0.1813 - accuracy: 0.4419\n",
      "Epoch 70/100\n",
      "304/304 [==============================] - 6s 18ms/step - loss: 0.1772 - accuracy: 0.4421\n",
      "Epoch 71/100\n",
      "304/304 [==============================] - 6s 18ms/step - loss: 0.1766 - accuracy: 0.4425\n",
      "Epoch 72/100\n",
      "304/304 [==============================] - 6s 18ms/step - loss: 0.1759 - accuracy: 0.4428\n",
      "Epoch 73/100\n",
      "304/304 [==============================] - 6s 18ms/step - loss: 0.1741 - accuracy: 0.4429\n",
      "Epoch 74/100\n",
      "304/304 [==============================] - 5s 18ms/step - loss: 0.1734 - accuracy: 0.4428\n",
      "Epoch 75/100\n",
      "304/304 [==============================] - 5s 18ms/step - loss: 0.1726 - accuracy: 0.4432\n",
      "Epoch 76/100\n",
      "304/304 [==============================] - 5s 18ms/step - loss: 0.1713 - accuracy: 0.4431\n",
      "Epoch 77/100\n",
      "304/304 [==============================] - 5s 17ms/step - loss: 0.1707 - accuracy: 0.4437\n",
      "Epoch 78/100\n",
      "304/304 [==============================] - 5s 18ms/step - loss: 0.1702 - accuracy: 0.4436\n",
      "Epoch 79/100\n",
      "304/304 [==============================] - 5s 18ms/step - loss: 0.1695 - accuracy: 0.4436\n",
      "Epoch 80/100\n",
      "304/304 [==============================] - 5s 18ms/step - loss: 0.1693 - accuracy: 0.4435\n",
      "Epoch 81/100\n",
      "304/304 [==============================] - 5s 18ms/step - loss: 0.1686 - accuracy: 0.4439\n",
      "Epoch 82/100\n",
      "304/304 [==============================] - 5s 17ms/step - loss: 0.1696 - accuracy: 0.4435\n",
      "Epoch 83/100\n",
      "304/304 [==============================] - 5s 17ms/step - loss: 0.1679 - accuracy: 0.4437\n",
      "Epoch 84/100\n",
      "304/304 [==============================] - 5s 17ms/step - loss: 0.1664 - accuracy: 0.4437\n",
      "Epoch 85/100\n",
      "304/304 [==============================] - 5s 17ms/step - loss: 0.1687 - accuracy: 0.4436\n",
      "Epoch 86/100\n",
      "304/304 [==============================] - 5s 16ms/step - loss: 0.1679 - accuracy: 0.4437\n",
      "Epoch 87/100\n",
      "304/304 [==============================] - 5s 17ms/step - loss: 0.1670 - accuracy: 0.4439\n",
      "Epoch 88/100\n",
      "304/304 [==============================] - 5s 17ms/step - loss: 0.1667 - accuracy: 0.4436\n",
      "Epoch 89/100\n",
      "304/304 [==============================] - 5s 17ms/step - loss: 0.1661 - accuracy: 0.4440\n",
      "Epoch 90/100\n",
      "304/304 [==============================] - 5s 17ms/step - loss: 0.1657 - accuracy: 0.4436\n",
      "Epoch 91/100\n",
      "304/304 [==============================] - 5s 17ms/step - loss: 0.1649 - accuracy: 0.4440\n",
      "Epoch 92/100\n",
      "304/304 [==============================] - 5s 17ms/step - loss: 0.1654 - accuracy: 0.4439\n",
      "Epoch 93/100\n",
      "304/304 [==============================] - 5s 17ms/step - loss: 0.1641 - accuracy: 0.4441\n",
      "Epoch 94/100\n",
      "304/304 [==============================] - 5s 17ms/step - loss: 0.1641 - accuracy: 0.4436\n",
      "Epoch 95/100\n",
      "304/304 [==============================] - 5s 17ms/step - loss: 0.1635 - accuracy: 0.4440\n",
      "Epoch 96/100\n",
      "304/304 [==============================] - 5s 17ms/step - loss: 0.1636 - accuracy: 0.4440\n",
      "Epoch 97/100\n",
      "304/304 [==============================] - 5s 17ms/step - loss: 0.1630 - accuracy: 0.4442\n",
      "Epoch 98/100\n",
      "304/304 [==============================] - 5s 17ms/step - loss: 0.1626 - accuracy: 0.4442\n",
      "Epoch 99/100\n",
      "304/304 [==============================] - 5s 17ms/step - loss: 0.1636 - accuracy: 0.4443\n",
      "Epoch 100/100\n",
      "304/304 [==============================] - 5s 17ms/step - loss: 0.1648 - accuracy: 0.4438\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f7d1cac7820>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inference 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_inference(sentence):\n",
    "    # 입력 문장 전처리\n",
    "    sentence = preprocess_korean_sentence(sentence)\n",
    "\n",
    "    # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가\n",
    "    sentence = tf.expand_dims(\n",
    "        START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "    # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수\n",
    "    # 처음에는 예측한 내용이 없으므로 시작 토큰만 별도 저장\n",
    "    output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "    # 디코더의 인퍼런스 단계 (auto-regressive 방식)\n",
    "    for i in range(MAX_LENGTH):\n",
    "        # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
    "        predictions = model(inputs=[sentence], training=False)\n",
    "        predictions = predictions[:, -1:, :]  # 마지막 예측만 사용\n",
    "\n",
    "        # 현재 예측한 단어의 정수 (예측된 값에서 argmax로 가장 큰 값을 선택)\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "        # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
    "        if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "            break\n",
    "\n",
    "        # 예측한 단어들을 지속적으로 output_sequence에 추가\n",
    "        output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "\n",
    "        # 예측한 단어를 입력 시퀀스에 추가\n",
    "        sentence = tf.concat([sentence, predicted_id], axis=-1)\n",
    "\n",
    "    return tf.squeeze(output_sequence, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def sentence_generation(sentence):\n",
    "  # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
    "  prediction = decoder_inference(sentence)\n",
    "\n",
    "  # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
    "  predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "  print('입력 : {}'.format(sentence))\n",
    "  print('출력 : {}'.format(predicted_sentence))\n",
    "\n",
    "  return predicted_sentence\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 입력에 따른 출력 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 오늘 날씨는\n",
      "출력 : 않은 좋아하고 인 것 같습니다\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'않은 좋아하고 인 것 같습니다'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('오늘 날씨는')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 배가 너무\n",
      "출력 : 와\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'와'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('배가 너무')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 오늘\n",
      "출력 : 은 시작도 돼\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'은 시작도 돼'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('오늘')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
