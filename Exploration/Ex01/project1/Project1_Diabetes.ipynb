{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. 데이터 가져오기\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "diabetes = load_diabetes()\n",
    "df_X = diabetes.data\n",
    "df_y = diabetes.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "X's type : <class 'numpy.ndarray'>\n",
       "y's type : <class 'numpy.ndarray'>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#2.& 3. 모델에 입력할 데이터 X y 준비하기 (이미 <class 'numpy.ndarray'> 이므로 따로 변환 X)\n",
    "print(\"X's type : \"+str(type(df_X)))\n",
    "print(\"y's type : \"+str(type(df_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. train, test 분리하기\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, test_size=0.2, random_state=2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "X.shape : (442, 10)\n",
       "y.shape : (442,)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#5. 모델 준비하기\n",
    "import numpy as np\n",
    "\n",
    "print(\"X.shape : \" + str(df_X.shape)) # 10개의 피처 확인\n",
    "print(\"y.shape : \" + str(df_y.shape))\n",
    "num_features = df_X.shape[1]\n",
    "\n",
    "np.random.seed(42)\n",
    "W = np.random.randn(num_features)\n",
    "b = np.random.randn()\n",
    "\n",
    "\n",
    "def Model(X, W=W, b=b):\n",
    "    predict = np.dot(X, W) + b\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. 손실함수 loss 정의하기\n",
    "\n",
    "def Loss(label, predict):\n",
    "    n = label.shape[0]\n",
    "    return np.sum((label - predict)**2) / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7. 기울기를 구하는 gradient 함수 구현하기\n",
    "\n",
    "def gradient(X, label, predict):\n",
    "    n = label.shape[0]\n",
    "    dW = 2 * np.dot(X.T, (predict - label)) / n\n",
    "    db = 2 * np.sum(predict - label) / n\n",
    "    return dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. 하이퍼 파라미터인 학습률 정하기\n",
    "learning_rate = [0.01, 0.1, 0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9. 모델 학습하기\n",
    "epoch = 5000\n",
    "losses_1, losses_2, losses_3 = [], [], []\n",
    "min_loss_1, min_loss_2, min_loss_3 = float('inf'), float('inf'), float('inf')\n",
    "best_W_1, best_b_1 = None, None\n",
    "best_W_2, best_b_2 = None, None\n",
    "best_W_3, best_b_3 = None, None\n",
    "for idx, lr in enumerate(learning_rate):\n",
    "    W_copy = W  # 새로 초기화\n",
    "    b_copy = b\n",
    "    losses = []\n",
    "    min_loss = float('inf')  # 현재 학습률에서 최소 손실값 초기화\n",
    "    best_W, best_b = None, None  # 최소 손실값에서의 W, b 저장\n",
    "    \n",
    "    for _ in range(epoch):\n",
    "        prediction = Model(X_train, W=W_copy, b=b_copy)\n",
    "        loss = Loss(y_train, prediction)\n",
    "        losses.append(loss)\n",
    "        \n",
    "        # 최소 손실값 갱신\n",
    "        if loss < min_loss:\n",
    "            min_loss = loss\n",
    "            best_W = W_copy.copy()  # 최소 손실값에서의 W 복사 저장\n",
    "            best_b = b_copy  # 최소 손실값에서의 b 저장\n",
    "        \n",
    "        dW, db = gradient(X_train, y_train, prediction)\n",
    "        W_copy -= lr * dW\n",
    "        b_copy -= lr * db\n",
    "\n",
    "    # 손실값 기록 및 최소 손실 모델 업데이트\n",
    "    if idx == 0:\n",
    "        losses_1 = losses\n",
    "        W_1, b_1 = W_copy, b_copy\n",
    "        min_loss_1 = min_loss\n",
    "        best_W_1, best_b_1 = best_W, best_b\n",
    "    elif idx == 1:\n",
    "        losses_2 = losses\n",
    "        W_2, b_2 = W_copy, b_copy\n",
    "        min_loss_2 = min_loss\n",
    "        best_W_2, best_b_2 = best_W, best_b\n",
    "    else:\n",
    "        losses_3 = losses\n",
    "        W_3, b_3 = W_copy, b_copy\n",
    "        min_loss_3 = min_loss\n",
    "        best_W_3, best_b_3 = best_W, best_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10. test데이터에 대한 성능 확인하기\n",
    "test_prediction_1 = Model(X_test, W=best_W_1, b=best_b_1)\n",
    "test_prediction_2 = Model(X_test, W=best_W_2, b=best_b_2)\n",
    "test_prediction_3 = Model(X_test, W=best_W_3, b=best_b_3)\n",
    "\n",
    "loss_1 = Loss(y_test, test_prediction_1)\n",
    "loss_2 = Loss(y_test, test_prediction_2)\n",
    "loss_3 = Loss(y_test, test_prediction_3)\n",
    "\n",
    "print(\"==========================================================================\")\n",
    "print(f\"Loss in test with learning rate = 0.01 : {loss_1} \\n  W : {W_1}\\n  b : {b_1}\\n\")\n",
    "print(f\"Loss in test with learning rate = 0.1 : {loss_2} \\n  W : {W_2}\\n  b : {b_2}\\n\")\n",
    "print(f\"Loss in test with learning rate = 1 : {loss_3} \\n  W : {W_3}\\n  b : {b_3}\\n\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(losses_1, label='lr=0.01')\n",
    "plt.plot(losses_2, label='lr=0.1')\n",
    "plt.plot(losses_3, label='lr=1')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Comparing different Learning rate')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#11. 정답 데이터와 예측한 데이터 시각화하기기\n",
    "fig, axes = plt.subplots(3, 1)\n",
    "\n",
    "# Learning Rate = 0.01\n",
    "axes[0].scatter(x=X_test[:, 0], y=y_test, color='black', label='True')\n",
    "axes[0].scatter(x=X_test[:, 0], y=test_prediction_1, color='red', label='Predicted')\n",
    "axes[0].set_title('Learning Rate = 0.01')\n",
    "axes[0].legend(loc='upper left', bbox_to_anchor=(1, 1), framealpha=0.5)\n",
    "\n",
    "# Learning Rate = 0.1\n",
    "axes[1].scatter(x=X_test[:, 0], y=y_test, color='black', label='True')\n",
    "axes[1].scatter(x=X_test[:, 0], y=test_prediction_2, color='red', label='Predicted')\n",
    "axes[1].set_title('Learning Rate = 0.1')\n",
    "axes[1].legend(loc='upper left', bbox_to_anchor=(1, 1), framealpha=0.5)\n",
    "\n",
    "# Learning Rate = 1\n",
    "axes[2].scatter(x=X_test[:, 0], y=y_test, color='black', label='True')\n",
    "axes[2].scatter(x=X_test[:, 0], y=test_prediction_3, color='red', label='Predicted')\n",
    "axes[2].set_title('Learning Rate = 1')\n",
    "axes[2].legend(loc='upper left', bbox_to_anchor=(1, 1), framealpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
